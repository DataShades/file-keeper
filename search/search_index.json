{"config":{"lang":["en"],"separator":"[\\s\\-\\.\\_]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>file-keeper provides an abstraction layer for storing and retrieving files, supporting various storage backends like local filesystems, cloud storage (S3, GCS), and more.  It simplifies file management by providing a consistent API regardless of the underlying storage.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install file-keeper using pip:</p> <pre><code>pip install file-keeper\n</code></pre> <p>Note</p> <p>To use specific storage adapters, you may need to install extra dependencies. Most standard adapters do not require extras, but some \u2013 like those interfacing with external cloud providers \u2013 do. Here's a table of available extras:</p> Storage Type Adapter Name Extras Driver AWS S3 <code>file_keeper:s3</code> <code>s3</code> boto3 Apache Libcloud <code>file_keeper:libcloud</code> <code>libcloud</code> apache-libcloud Apache OpenDAL <code>file_keeper:opendal</code> <code>opendal</code> opendal Azure Blob Storage <code>file_keeper:azure_blob</code> <code>azure</code> azure-storage-blob Google Cloud Storage <code>file_keeper:gcs</code> <code>gcs</code> google-cloud-storage Redis <code>file_keeper:redis</code> <code>redis</code> redis SQLAlchemy <code>file_keeper:sqlalchemy</code> <code>sqlalchemy</code> SQLAlchemy <p>For example, to install file-keeper with S3 support:</p> <pre><code>pip install 'file-keeper[s3]'\n</code></pre>"},{"location":"#basic-configuration-and-usage-fs-adapter","title":"Basic configuration and usage (FS adapter)","text":"<p>Let's start with a simple example using the local filesystem (FS) adapter.</p> <p>Example</p> <pre><code>from file_keeper import make_storage, make_upload\n\n# Create a storage instance.  The 'path' setting specifies the root directory\n# for storing files. 'initialize' will automatically create the directory\n# if it doesn't exist.\nstorage = make_storage(\n    \"my_fs_storage\",  # A name for your storage (for logging/debugging)\n    {\n        \"type\": \"file_keeper:fs\",\n        \"path\": \"/tmp/my_filekeeper_files\",\n        \"initialize\": True,\n    },\n)\n\n# Create an upload object from a byte string.\nupload = make_upload(b\"Hello, file-keeper!\")\n\n# Upload the file.  This returns a FileData object containing information\n# about the uploaded file.\nfile_data = storage.upload(\"my_file.txt\", upload)\n\n# Print the file data.\nprint(file_data)\n\n# The file is now stored in /tmp/my_filekeeper_files/my_file.txt\n\n# Get the content of file using corresponding FileData object\ncontent: bytes = storage.content(file_data)\n</code></pre> <p>Explanation:</p> <ul> <li><code>make_storage()</code>: Creates a storage instance with the specified configuration.</li> <li><code>make_upload()</code>: Creates an <code>Upload</code> object from the data you want to store.</li> <li><code>storage.upload()</code>: Uploads the data to the storage.</li> <li><code>FileData</code>:  A dataclass that contains metadata about the uploaded file, including its location, size, content type, and hash.</li> <li><code>storage.content()</code>: Locates file using <code>FileData</code> and returs byte string with its content</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Utilities available for import directly from the <code>file_keeper</code> module.</p>"},{"location":"api/#file_keeper.make_storage","title":"<code>make_storage(name, settings)</code>","text":"<p>Initialize storage instance with specified settings.</p> <p>Storage adapter is defined by <code>type</code> key of the settings. The rest of settings depends on the specific adapter.</p> PARAMETER DESCRIPTION <code>name</code> <p>name of the storage</p> <p> TYPE: <code>str</code> </p> <code>settings</code> <p>configuration for the storage</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Storage</code> <p>storage instance</p> RAISES DESCRIPTION <code>UnknownAdapterError</code> <p>storage adapter is not registered</p> Example <pre><code>storage = make_storage(\"memo\", {\"type\": \"files:redis\"})\n</code></pre> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def make_storage(name: str, settings: dict[str, Any]) -&gt; Storage:\n    \"\"\"Initialize storage instance with specified settings.\n\n    Storage adapter is defined by `type` key of the settings. The rest of\n    settings depends on the specific adapter.\n\n    Args:\n        name: name of the storage\n        settings: configuration for the storage\n\n    Returns:\n        storage instance\n\n    Raises:\n        exceptions.UnknownAdapterError: storage adapter is not registered\n\n    Example:\n        ```\n        storage = make_storage(\"memo\", {\"type\": \"files:redis\"})\n        ```\n\n    \"\"\"\n    adapter_type = settings.pop(\"type\", None)\n    adapter = adapters.get(adapter_type)\n    if not adapter:\n        raise exceptions.UnknownAdapterError(adapter_type)\n\n    settings.setdefault(\"name\", name)\n\n    return adapter(settings)\n</code></pre>"},{"location":"api/#file_keeper.make_upload","title":"<code>make_upload(value)</code>","text":"<p>Convert value into Upload object.</p> <p>Use this function for simple and reliable initialization of Upload object. Avoid creating Upload manually, unless you are 100% sure you can provide correct MIMEtype, size and stream.</p> PARAMETER DESCRIPTION <code>value</code> <p>content of the file</p> <p> TYPE: <code>Any</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>content has unsupported type</p> RETURNS DESCRIPTION <code>Upload</code> <p>upload object with specified content</p> Example <pre><code>upload = storage.upload(\"file.txt\", make_upload(b\"hello world\"))\n</code></pre> Source code in <code>src/file_keeper/core/upload.py</code> <pre><code>def make_upload(value: Any) -&gt; Upload:\n    \"\"\"Convert value into [Upload][file_keeper.Upload] object.\n\n    Use this function for simple and reliable initialization of\n    [Upload][file_keeper.Upload] object. Avoid creating\n    [Upload][file_keeper.Upload] manually, unless you are 100% sure you can\n    provide correct MIMEtype, size and stream.\n\n    Args:\n        value: content of the file\n\n    Raises:\n        TypeError: content has unsupported type\n\n    Returns:\n        upload object with specified content\n\n    Example:\n        ```python\n        upload = storage.upload(\"file.txt\", make_upload(b\"hello world\"))\n        ```\n\n    \"\"\"\n    if isinstance(value, Upload):\n        return value\n\n    initial_type: type = type(value)  # pyright: ignore[reportUnknownVariableType]\n\n    fallback_factory = None\n    for t in upload_factories:\n        if initial_type is t:\n            transformed_value = upload_factories[t](value)\n            if transformed_value is not None:\n                value = transformed_value\n                break\n\n        if not fallback_factory and issubclass(initial_type, t):\n            fallback_factory = upload_factories[t]\n\n    else:\n        if fallback_factory:\n            value = fallback_factory(value)\n\n    # ideal situation: factory produced the Upload object\n    if isinstance(value, Upload):\n        return value\n\n    if isinstance(value, (bytes, bytearray)):\n        value = BytesIO(value)\n\n    # convenient situation: factory produced binary buffer and we know how to\n    # transform it into an Upload. Factories will choose this option to avoid\n    # repeating mimetype detection logic\n    if isinstance(value, (BytesIO, BufferedReader)):\n        mime = magic.from_buffer(value.read(SAMPLE_SIZE), True)\n        _ = value.seek(0, 2)\n        size = value.tell()\n        _ = value.seek(0)\n\n        return Upload(value, getattr(value, \"name\", \"\"), size, mime)\n\n    raise TypeError(type(value))\n</code></pre>"},{"location":"api/#file_keeper.Storage","title":"<code>Storage</code>","text":"<p>Base class for storage implementation.</p> PARAMETER DESCRIPTION <code>settings</code> <p>storage configuration</p> <p> TYPE: <code>Mapping[str, Any] | Settings</code> </p> Example <pre><code>class MyStorage(Storage):\n    SettingsFactory = MySettings\n    UploaderFactory = MyUploader\n    ManagerFactory = MyManager\n    ReaderFactory = MyReader\n</code></pre> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>class Storage(ABC):  # noqa: B024\n    \"\"\"Base class for storage implementation.\n\n    Args:\n        settings: storage configuration\n\n    Example:\n        ```py\n        class MyStorage(Storage):\n            SettingsFactory = MySettings\n            UploaderFactory = MyUploader\n            ManagerFactory = MyManager\n            ReaderFactory = MyReader\n        ```\n    \"\"\"\n\n    # do not show storage adapter\n    hidden: bool = False\n    \"\"\"Flag that marks unsafe/experimental storages.\"\"\"\n\n    capabilities: Capability = Capability.NONE\n    \"\"\"Operations supported by storage. Computed from capabilities of\n    services during storage initialization.\"\"\"\n\n    SettingsFactory: ClassVar[type[Settings]] = Settings\n    \"\"\"Factory class for storage settings.\"\"\"\n    UploaderFactory: ClassVar[type[Uploader]] = Uploader\n    \"\"\"Factory class for uploader service.\"\"\"\n    ManagerFactory: ClassVar[type[Manager]] = Manager\n    \"\"\"Factory class for manager service.\"\"\"\n    ReaderFactory: ClassVar[type[Reader]] = Reader\n    \"\"\"Factory class for reader service.\"\"\"\n\n    @override\n    def __str__(self) -&gt; str:\n        return self.settings.name\n\n    def __init__(self, settings: Mapping[str, Any] | Settings, /):\n        self.settings = self.configure(settings)\n        self.uploader = self.make_uploader()\n        self.manager = self.make_manager()\n        self.reader = self.make_reader()\n\n        self.capabilities = self.compute_capabilities()\n\n    def make_uploader(self):\n        \"\"\"Initialize [uploader][file_keeper.Uploader] service.\"\"\"\n        return self.UploaderFactory(self)\n\n    def make_manager(self):\n        \"\"\"Initialize [manager][file_keeper.Manager] service.\"\"\"\n        return self.ManagerFactory(self)\n\n    def make_reader(self):\n        \"\"\"Initialize [reader][file_keeper.Reader] service.\"\"\"\n        return self.ReaderFactory(self)\n\n    @classmethod\n    def configure(cls, settings: Mapping[str, Any] | Settings) -&gt; Settings:\n        \"\"\"Initialize storage configuration.\n\n        This method is responsible for transforming mapping with options into\n        storage's settings. It also can initialize additional services and\n        perform extra work, like verifying that storage is ready to accept\n        uploads.\n\n        Args:\n            settings: mapping with storage configuration\n\n        \"\"\"\n        if isinstance(settings, Settings):\n            return settings\n\n        return cls.SettingsFactory.from_dict(settings)\n\n    def compute_capabilities(self) -&gt; Capability:\n        \"\"\"Computes the capabilities of the storage based on its services.\"\"\"\n        result = self.uploader.capabilities | self.manager.capabilities | self.reader.capabilities\n\n        for name in self.settings.disabled_capabilities:\n            result = result.exclude(Capability[name])\n\n        return result\n\n    def supports(self, operation: Capability) -&gt; bool:\n        \"\"\"Check whether the storage supports operation.\"\"\"\n        return self.capabilities.can(operation)\n\n    def supports_synthetic(self, operation: Capability, dest: Storage) -&gt; bool:\n        \"\"\"Check if the storage can emulate operation using other operations.\"\"\"\n        if operation is Capability.RANGE:\n            return self.supports(Capability.STREAM)\n\n        if operation is Capability.COPY:\n            return self.supports(Capability.STREAM) and dest.supports(\n                Capability.CREATE,\n            )\n\n        if operation is Capability.MOVE:\n            return self.supports(\n                Capability.STREAM | Capability.REMOVE,\n            ) and dest.supports(Capability.CREATE)\n\n        if operation is Capability.COMPOSE:\n            return self.supports(Capability.STREAM) and dest.supports(\n                Capability.CREATE | Capability.APPEND | Capability.REMOVE\n            )\n\n        return False\n\n    def full_path(self, location: types.Location, /, **kwargs: Any) -&gt; str:\n        \"\"\"Compute path to the file from the storage's root.\n\n        Args:\n            location: location of the file object\n            **kwargs: exra parameters for custom storages\n\n        Returns:\n            full path required to access location\n        \"\"\"\n        return os.path.join(self.settings.path, location)\n\n    def prepare_location(\n        self, location: str, upload_or_data: data.BaseData | Upload | None = None, /, **kwargs: Any\n    ) -&gt; types.Location:\n        \"\"\"Transform and sanitize location using configured functions.\"\"\"\n        for name in self.settings.location_transformers:\n            if transformer := location_transformers.get(name):\n                location = transformer(location, upload_or_data, kwargs)\n            else:\n                raise exceptions.LocationTransformerError(name)\n\n        return types.Location(location)\n\n    def file_as_upload(self, data: data.FileData, **kwargs: Any) -&gt; Upload:\n        \"\"\"Make an [Upload][file_keeper.Upload] with file content.\n\n        Args:\n            data: The FileData object to wrap into Upload\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        stream = self.stream(data, **kwargs)\n        stream = cast(types.PStream, stream) if hasattr(stream, \"read\") else utils.IterableBytesReader(stream)\n\n        return Upload(\n            stream,\n            data.location,\n            data.size,\n            data.content_type,\n        )\n\n    @requires_capability(Capability.CREATE)\n    def upload(self, location: types.Location, upload: Upload, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Upload file using single stream.\n\n        Args:\n            location: The destination location for the upload.\n            upload: The Upload object containing the file data.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.upload(location, upload, kwargs)\n\n    @requires_capability(Capability.RESUMABLE)\n    def resumable_start(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Prepare everything for resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.resumable_start(data, kwargs)\n\n    @requires_capability(Capability.RESUMABLE)\n    def resumable_refresh(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Show details of the incomplete resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.resumable_refresh(data, kwargs)\n\n    @requires_capability(Capability.RESUMABLE)\n    def resumable_resume(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Resume the interrupted resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.resumable_resume(data, kwargs)\n\n    @requires_capability(Capability.RESUMABLE)\n    def resumable_remove(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n        \"\"\"Remove incomplete resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.resumable_remove(data, kwargs)\n\n    @requires_capability(Capability.MULTIPART)\n    def multipart_start(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Prepare everything for multipart upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.multipart_start(data, kwargs)\n\n    @requires_capability(Capability.MULTIPART)\n    def multipart_refresh(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Show details of the incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.multipart_refresh(data, kwargs)\n\n    @requires_capability(Capability.MULTIPART)\n    def multipart_update(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Add data to the incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.multipart_update(data, kwargs)\n\n    @requires_capability(Capability.MULTIPART)\n    def multipart_complete(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Verify file integrity and finalize incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.multipart_complete(data, kwargs)\n\n    @requires_capability(Capability.MULTIPART)\n    def multipart_remove(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n        \"\"\"Interrupt and remove incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            **kwargs: Additional metadata for the upload.\n        \"\"\"\n        return self.uploader.multipart_remove(data, kwargs)\n\n    @requires_capability(Capability.EXISTS)\n    def exists(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n        \"\"\"Check if file exists in the storage.\n\n        Args:\n            data: The FileData object representing the file to check.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.exists(data, kwargs)\n\n    @requires_capability(Capability.REMOVE)\n    def remove(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n        \"\"\"Remove file from the storage.\n\n        Args:\n            data: The FileData object representing the file to remove.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.remove(data, kwargs)\n\n    @requires_capability(Capability.SCAN)\n    def scan(self, **kwargs: Any) -&gt; Iterable[str]:\n        \"\"\"List all locations(filenames) in storage.\n\n        Args:\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.scan(kwargs)\n\n    @requires_capability(Capability.ANALYZE)\n    def analyze(self, location: types.Location, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Return file details.\n\n        Args:\n            location: The location of the file to analyze.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.analyze(location, kwargs)\n\n    @requires_capability(Capability.SIGNED)\n    def signed(\n        self,\n        action: types.SignedAction,\n        duration: int,\n        location: types.Location,\n        **kwargs: Any,\n    ) -&gt; str:\n        \"\"\"Make an URL for signed action.\n\n        Args:\n            action: The action to sign (e.g., \"upload\", \"download\").\n            duration: The duration for which the signed URL is valid.\n            location: The location of the file to sign.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.signed(action, duration, location, kwargs)\n\n    @requires_capability(Capability.STREAM)\n    def stream(self, data: data.FileData, /, **kwargs: Any) -&gt; Iterable[bytes]:\n        \"\"\"Return byte-stream of the file content.\n\n        Args:\n            data: The FileData object representing the file to stream.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.reader.stream(data, kwargs)\n\n    @requires_capability(Capability.RANGE)\n    def range(self, data: data.FileData, start: int = 0, end: int | None = None, /, **kwargs: Any) -&gt; Iterable[bytes]:\n        \"\"\"Return slice of the file content.\n\n        Args:\n            data: The FileData object representing the file to read.\n            start: The starting byte offset.\n            end: The ending byte offset (inclusive).\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.reader.range(data, start, end, kwargs)\n\n    def range_synthetic(\n        self, data: data.FileData, start: int = 0, end: int | None = None, /, **kwargs: Any\n    ) -&gt; Iterable[bytes]:\n        \"\"\"Generic implementation of range operation that relies on [STREAM][file_keeper.Capability.STREAM].\n\n        Args:\n            data: The FileData object representing the file to read.\n            start: The starting byte offset.\n            end: The ending byte offset (inclusive).\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        if end is None:\n            end = cast(int, float(\"inf\"))\n\n        end -= start\n        if end &lt;= 0:\n            return\n\n        for chunk in self.stream(data, **kwargs):\n            if start &gt; 0:\n                start -= len(chunk)\n                if start &lt; 0:\n                    chunk = chunk[start:]  # noqa: PLW2901\n                else:\n                    continue\n\n            yield chunk[: end and None]\n            end -= len(chunk)\n            if end &lt;= 0:\n                break\n\n    @requires_capability(Capability.STREAM)\n    def content(self, data: data.FileData, /, **kwargs: Any) -&gt; bytes:\n        \"\"\"Return file content as a single byte object.\n\n        Args:\n            data: The FileData object representing the file to read.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.reader.content(data, kwargs)\n\n    @requires_capability(Capability.APPEND)\n    def append(self, data: data.FileData, upload: Upload, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Append content to existing file.\n\n        Args:\n            data: The FileData object representing the file to append to.\n            upload: The Upload object containing the content to append.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.append(data, upload, kwargs)\n\n    @requires_capability(Capability.COPY)\n    def copy(self, location: types.Location, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Copy file inside the storage.\n\n        Args:\n            location: The destination location for the copied file.\n            data: The FileData object representing the file to copy.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.copy(location, data, kwargs)\n\n    def copy_synthetic(\n        self, location: types.Location, data: data.FileData, dest_storage: Storage, /, **kwargs: Any\n    ) -&gt; data.FileData:\n        \"\"\"Generic implementation of the copy operation that relies on [CREATE][file_keeper.Capability.CREATE].\n\n        Args:\n            location: The destination location for the copied file.\n            data: The FileData object representing the file to copy.\n            dest_storage: The destination storage\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return dest_storage.upload(\n            location,\n            self.file_as_upload(data, **kwargs),\n            **kwargs,\n        )\n\n    @requires_capability(Capability.MOVE)\n    def move(self, location: types.Location, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Move file to a different location inside the storage.\n\n        Args:\n            location: The destination location for the moved file.\n            data: The FileData object representing the file to move.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.move(location, data, kwargs)\n\n    def move_synthetic(\n        self, location: types.Location, data: data.FileData, dest_storage: Storage, /, **kwargs: Any\n    ) -&gt; data.FileData:\n        \"\"\"Generic implementation of move operation.\n\n        Relies on [CREATE][file_keeper.Capability.CREATE] and\n        [REMOVE][file_keeper.Capability.REMOVE].\n\n        Args:\n            location: The destination location for the moved file.\n            data: The FileData object representing the file to move.\n            dest_storage: The destination storage\n            **kwargs: Additional metadata for the operation.\n\n        \"\"\"\n        result = dest_storage.upload(location, self.file_as_upload(data, **kwargs), **kwargs)\n        self.remove(data)\n        return result\n\n    @requires_capability(Capability.COMPOSE)\n    def compose(self, location: types.Location, /, *files: data.FileData, **kwargs: Any) -&gt; data.FileData:\n        \"\"\"Combine multiple files into a new file.\n\n        Args:\n            location: The destination location for the composed file.\n            *files: FileData objects representing the files to combine.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        return self.manager.compose(location, files, kwargs)\n\n    def compose_synthetic(\n        self, location: types.Location, dest_storage: Storage, /, *files: data.FileData, **kwargs: Any\n    ) -&gt; data.FileData:\n        \"\"\"Generic composition that relies on [APPEND][file_keeper.Capability.APPEND].\n\n        Args:\n            location: The destination location for the composed file.\n            dest_storage: The destination storage\n            *files: FileData objects representing the files to combine.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        result = dest_storage.upload(location, make_upload(b\"\"), **kwargs)\n\n        # when first append succeeded with the fragment of the file added\n        # in the storage, and the following append failed, this incomplete\n        # fragment must be removed.\n        #\n        # Expected reasons of failure are:\n        #\n        # * one of the source fiels is missing\n        # * file will go over the size limit after the following append\n        try:\n            for item in files:\n                result = dest_storage.append(\n                    result,\n                    self.file_as_upload(item, **kwargs),\n                    **kwargs,\n                )\n        except (exceptions.MissingFileError, exceptions.UploadError):\n            self.remove(result, **kwargs)\n            raise\n\n        return result\n\n    def one_time_link(self, data: data.FileData, /, **kwargs: Any) -&gt; str | None:\n        \"\"\"Return one-time download link.\n\n        Args:\n            data: The FileData object representing the file.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        if self.supports(Capability.ONE_TIME_LINK):\n            return self.reader.one_time_link(data, kwargs)\n\n    def temporal_link(self, data: data.FileData, duration: int, /, **kwargs: Any) -&gt; str | None:\n        \"\"\"Return temporal download link.\n\n        Args:\n            data: The FileData object representing the file.\n            duration: The duration for which the link is valid.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        if self.supports(Capability.TEMPORAL_LINK):\n            return self.reader.temporal_link(data, duration, kwargs)\n\n    def permanent_link(self, data: data.FileData, /, **kwargs: Any) -&gt; str | None:\n        \"\"\"Return permanent download link.\n\n        Args:\n            data: The FileData object representing the file.\n            **kwargs: Additional metadata for the operation.\n        \"\"\"\n        if self.supports(Capability.PERMANENT_LINK):\n            return self.reader.permanent_link(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.ManagerFactory","title":"<code>ManagerFactory = Manager</code>  <code>class-attribute</code>","text":"<p>Factory class for manager service.</p>"},{"location":"api/#file_keeper.Storage.ReaderFactory","title":"<code>ReaderFactory = Reader</code>  <code>class-attribute</code>","text":"<p>Factory class for reader service.</p>"},{"location":"api/#file_keeper.Storage.SettingsFactory","title":"<code>SettingsFactory = Settings</code>  <code>class-attribute</code>","text":"<p>Factory class for storage settings.</p>"},{"location":"api/#file_keeper.Storage.UploaderFactory","title":"<code>UploaderFactory = Uploader</code>  <code>class-attribute</code>","text":"<p>Factory class for uploader service.</p>"},{"location":"api/#file_keeper.Storage.capabilities","title":"<code>capabilities = self.compute_capabilities()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Operations supported by storage. Computed from capabilities of services during storage initialization.</p>"},{"location":"api/#file_keeper.Storage.hidden","title":"<code>hidden = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Flag that marks unsafe/experimental storages.</p>"},{"location":"api/#file_keeper.Storage.analyze","title":"<code>analyze(location, /, **kwargs)</code>","text":"<p>Return file details.</p> PARAMETER DESCRIPTION <code>location</code> <p>The location of the file to analyze.</p> <p> TYPE: <code>Location</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.ANALYZE)\ndef analyze(self, location: types.Location, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Return file details.\n\n    Args:\n        location: The location of the file to analyze.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.analyze(location, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.append","title":"<code>append(data, upload, /, **kwargs)</code>","text":"<p>Append content to existing file.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to append to.</p> <p> TYPE: <code>FileData</code> </p> <code>upload</code> <p>The Upload object containing the content to append.</p> <p> TYPE: <code>Upload</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.APPEND)\ndef append(self, data: data.FileData, upload: Upload, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Append content to existing file.\n\n    Args:\n        data: The FileData object representing the file to append to.\n        upload: The Upload object containing the content to append.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.append(data, upload, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.compose","title":"<code>compose(location, /, *files, **kwargs)</code>","text":"<p>Combine multiple files into a new file.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the composed file.</p> <p> TYPE: <code>Location</code> </p> <code>*files</code> <p>FileData objects representing the files to combine.</p> <p> TYPE: <code>FileData</code> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.COMPOSE)\ndef compose(self, location: types.Location, /, *files: data.FileData, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Combine multiple files into a new file.\n\n    Args:\n        location: The destination location for the composed file.\n        *files: FileData objects representing the files to combine.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.compose(location, files, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.compose_synthetic","title":"<code>compose_synthetic(location, dest_storage, /, *files, **kwargs)</code>","text":"<p>Generic composition that relies on APPEND.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the composed file.</p> <p> TYPE: <code>Location</code> </p> <code>dest_storage</code> <p>The destination storage</p> <p> TYPE: <code>Storage</code> </p> <code>*files</code> <p>FileData objects representing the files to combine.</p> <p> TYPE: <code>FileData</code> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def compose_synthetic(\n    self, location: types.Location, dest_storage: Storage, /, *files: data.FileData, **kwargs: Any\n) -&gt; data.FileData:\n    \"\"\"Generic composition that relies on [APPEND][file_keeper.Capability.APPEND].\n\n    Args:\n        location: The destination location for the composed file.\n        dest_storage: The destination storage\n        *files: FileData objects representing the files to combine.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    result = dest_storage.upload(location, make_upload(b\"\"), **kwargs)\n\n    # when first append succeeded with the fragment of the file added\n    # in the storage, and the following append failed, this incomplete\n    # fragment must be removed.\n    #\n    # Expected reasons of failure are:\n    #\n    # * one of the source fiels is missing\n    # * file will go over the size limit after the following append\n    try:\n        for item in files:\n            result = dest_storage.append(\n                result,\n                self.file_as_upload(item, **kwargs),\n                **kwargs,\n            )\n    except (exceptions.MissingFileError, exceptions.UploadError):\n        self.remove(result, **kwargs)\n        raise\n\n    return result\n</code></pre>"},{"location":"api/#file_keeper.Storage.compute_capabilities","title":"<code>compute_capabilities()</code>","text":"<p>Computes the capabilities of the storage based on its services.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def compute_capabilities(self) -&gt; Capability:\n    \"\"\"Computes the capabilities of the storage based on its services.\"\"\"\n    result = self.uploader.capabilities | self.manager.capabilities | self.reader.capabilities\n\n    for name in self.settings.disabled_capabilities:\n        result = result.exclude(Capability[name])\n\n    return result\n</code></pre>"},{"location":"api/#file_keeper.Storage.configure","title":"<code>configure(settings)</code>  <code>classmethod</code>","text":"<p>Initialize storage configuration.</p> <p>This method is responsible for transforming mapping with options into storage's settings. It also can initialize additional services and perform extra work, like verifying that storage is ready to accept uploads.</p> PARAMETER DESCRIPTION <code>settings</code> <p>mapping with storage configuration</p> <p> TYPE: <code>Mapping[str, Any] | Settings</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@classmethod\ndef configure(cls, settings: Mapping[str, Any] | Settings) -&gt; Settings:\n    \"\"\"Initialize storage configuration.\n\n    This method is responsible for transforming mapping with options into\n    storage's settings. It also can initialize additional services and\n    perform extra work, like verifying that storage is ready to accept\n    uploads.\n\n    Args:\n        settings: mapping with storage configuration\n\n    \"\"\"\n    if isinstance(settings, Settings):\n        return settings\n\n    return cls.SettingsFactory.from_dict(settings)\n</code></pre>"},{"location":"api/#file_keeper.Storage.content","title":"<code>content(data, /, **kwargs)</code>","text":"<p>Return file content as a single byte object.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to read.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.STREAM)\ndef content(self, data: data.FileData, /, **kwargs: Any) -&gt; bytes:\n    \"\"\"Return file content as a single byte object.\n\n    Args:\n        data: The FileData object representing the file to read.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.reader.content(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.copy","title":"<code>copy(location, data, /, **kwargs)</code>","text":"<p>Copy file inside the storage.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the copied file.</p> <p> TYPE: <code>Location</code> </p> <code>data</code> <p>The FileData object representing the file to copy.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.COPY)\ndef copy(self, location: types.Location, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Copy file inside the storage.\n\n    Args:\n        location: The destination location for the copied file.\n        data: The FileData object representing the file to copy.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.copy(location, data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.copy_synthetic","title":"<code>copy_synthetic(location, data, dest_storage, /, **kwargs)</code>","text":"<p>Generic implementation of the copy operation that relies on CREATE.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the copied file.</p> <p> TYPE: <code>Location</code> </p> <code>data</code> <p>The FileData object representing the file to copy.</p> <p> TYPE: <code>FileData</code> </p> <code>dest_storage</code> <p>The destination storage</p> <p> TYPE: <code>Storage</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def copy_synthetic(\n    self, location: types.Location, data: data.FileData, dest_storage: Storage, /, **kwargs: Any\n) -&gt; data.FileData:\n    \"\"\"Generic implementation of the copy operation that relies on [CREATE][file_keeper.Capability.CREATE].\n\n    Args:\n        location: The destination location for the copied file.\n        data: The FileData object representing the file to copy.\n        dest_storage: The destination storage\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return dest_storage.upload(\n        location,\n        self.file_as_upload(data, **kwargs),\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/#file_keeper.Storage.exists","title":"<code>exists(data, /, **kwargs)</code>","text":"<p>Check if file exists in the storage.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to check.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.EXISTS)\ndef exists(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n    \"\"\"Check if file exists in the storage.\n\n    Args:\n        data: The FileData object representing the file to check.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.exists(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.file_as_upload","title":"<code>file_as_upload(data, **kwargs)</code>","text":"<p>Make an Upload with file content.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object to wrap into Upload</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def file_as_upload(self, data: data.FileData, **kwargs: Any) -&gt; Upload:\n    \"\"\"Make an [Upload][file_keeper.Upload] with file content.\n\n    Args:\n        data: The FileData object to wrap into Upload\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    stream = self.stream(data, **kwargs)\n    stream = cast(types.PStream, stream) if hasattr(stream, \"read\") else utils.IterableBytesReader(stream)\n\n    return Upload(\n        stream,\n        data.location,\n        data.size,\n        data.content_type,\n    )\n</code></pre>"},{"location":"api/#file_keeper.Storage.full_path","title":"<code>full_path(location, /, **kwargs)</code>","text":"<p>Compute path to the file from the storage's root.</p> PARAMETER DESCRIPTION <code>location</code> <p>location of the file object</p> <p> TYPE: <code>Location</code> </p> <code>**kwargs</code> <p>exra parameters for custom storages</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>str</code> <p>full path required to access location</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def full_path(self, location: types.Location, /, **kwargs: Any) -&gt; str:\n    \"\"\"Compute path to the file from the storage's root.\n\n    Args:\n        location: location of the file object\n        **kwargs: exra parameters for custom storages\n\n    Returns:\n        full path required to access location\n    \"\"\"\n    return os.path.join(self.settings.path, location)\n</code></pre>"},{"location":"api/#file_keeper.Storage.make_manager","title":"<code>make_manager()</code>","text":"<p>Initialize manager service.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def make_manager(self):\n    \"\"\"Initialize [manager][file_keeper.Manager] service.\"\"\"\n    return self.ManagerFactory(self)\n</code></pre>"},{"location":"api/#file_keeper.Storage.make_reader","title":"<code>make_reader()</code>","text":"<p>Initialize reader service.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def make_reader(self):\n    \"\"\"Initialize [reader][file_keeper.Reader] service.\"\"\"\n    return self.ReaderFactory(self)\n</code></pre>"},{"location":"api/#file_keeper.Storage.make_uploader","title":"<code>make_uploader()</code>","text":"<p>Initialize uploader service.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def make_uploader(self):\n    \"\"\"Initialize [uploader][file_keeper.Uploader] service.\"\"\"\n    return self.UploaderFactory(self)\n</code></pre>"},{"location":"api/#file_keeper.Storage.move","title":"<code>move(location, data, /, **kwargs)</code>","text":"<p>Move file to a different location inside the storage.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the moved file.</p> <p> TYPE: <code>Location</code> </p> <code>data</code> <p>The FileData object representing the file to move.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.MOVE)\ndef move(self, location: types.Location, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Move file to a different location inside the storage.\n\n    Args:\n        location: The destination location for the moved file.\n        data: The FileData object representing the file to move.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.move(location, data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.move_synthetic","title":"<code>move_synthetic(location, data, dest_storage, /, **kwargs)</code>","text":"<p>Generic implementation of move operation.</p> <p>Relies on CREATE and REMOVE.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the moved file.</p> <p> TYPE: <code>Location</code> </p> <code>data</code> <p>The FileData object representing the file to move.</p> <p> TYPE: <code>FileData</code> </p> <code>dest_storage</code> <p>The destination storage</p> <p> TYPE: <code>Storage</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def move_synthetic(\n    self, location: types.Location, data: data.FileData, dest_storage: Storage, /, **kwargs: Any\n) -&gt; data.FileData:\n    \"\"\"Generic implementation of move operation.\n\n    Relies on [CREATE][file_keeper.Capability.CREATE] and\n    [REMOVE][file_keeper.Capability.REMOVE].\n\n    Args:\n        location: The destination location for the moved file.\n        data: The FileData object representing the file to move.\n        dest_storage: The destination storage\n        **kwargs: Additional metadata for the operation.\n\n    \"\"\"\n    result = dest_storage.upload(location, self.file_as_upload(data, **kwargs), **kwargs)\n    self.remove(data)\n    return result\n</code></pre>"},{"location":"api/#file_keeper.Storage.multipart_complete","title":"<code>multipart_complete(data, /, **kwargs)</code>","text":"<p>Verify file integrity and finalize incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.MULTIPART)\ndef multipart_complete(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Verify file integrity and finalize incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.multipart_complete(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.multipart_refresh","title":"<code>multipart_refresh(data, /, **kwargs)</code>","text":"<p>Show details of the incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.MULTIPART)\ndef multipart_refresh(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Show details of the incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.multipart_refresh(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.multipart_remove","title":"<code>multipart_remove(data, /, **kwargs)</code>","text":"<p>Interrupt and remove incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.MULTIPART)\ndef multipart_remove(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n    \"\"\"Interrupt and remove incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.multipart_remove(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.multipart_start","title":"<code>multipart_start(data, /, **kwargs)</code>","text":"<p>Prepare everything for multipart upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.MULTIPART)\ndef multipart_start(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Prepare everything for multipart upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.multipart_start(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.multipart_update","title":"<code>multipart_update(data, /, **kwargs)</code>","text":"<p>Add data to the incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.MULTIPART)\ndef multipart_update(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Add data to the incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.multipart_update(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.one_time_link","title":"<code>one_time_link(data, /, **kwargs)</code>","text":"<p>Return one-time download link.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def one_time_link(self, data: data.FileData, /, **kwargs: Any) -&gt; str | None:\n    \"\"\"Return one-time download link.\n\n    Args:\n        data: The FileData object representing the file.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    if self.supports(Capability.ONE_TIME_LINK):\n        return self.reader.one_time_link(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.permanent_link","title":"<code>permanent_link(data, /, **kwargs)</code>","text":"<p>Return permanent download link.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def permanent_link(self, data: data.FileData, /, **kwargs: Any) -&gt; str | None:\n    \"\"\"Return permanent download link.\n\n    Args:\n        data: The FileData object representing the file.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    if self.supports(Capability.PERMANENT_LINK):\n        return self.reader.permanent_link(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.prepare_location","title":"<code>prepare_location(location, upload_or_data=None, /, **kwargs)</code>","text":"<p>Transform and sanitize location using configured functions.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def prepare_location(\n    self, location: str, upload_or_data: data.BaseData | Upload | None = None, /, **kwargs: Any\n) -&gt; types.Location:\n    \"\"\"Transform and sanitize location using configured functions.\"\"\"\n    for name in self.settings.location_transformers:\n        if transformer := location_transformers.get(name):\n            location = transformer(location, upload_or_data, kwargs)\n        else:\n            raise exceptions.LocationTransformerError(name)\n\n    return types.Location(location)\n</code></pre>"},{"location":"api/#file_keeper.Storage.range","title":"<code>range(data, start=0, end=None, /, **kwargs)</code>","text":"<p>Return slice of the file content.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to read.</p> <p> TYPE: <code>FileData</code> </p> <code>start</code> <p>The starting byte offset.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>end</code> <p>The ending byte offset (inclusive).</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.RANGE)\ndef range(self, data: data.FileData, start: int = 0, end: int | None = None, /, **kwargs: Any) -&gt; Iterable[bytes]:\n    \"\"\"Return slice of the file content.\n\n    Args:\n        data: The FileData object representing the file to read.\n        start: The starting byte offset.\n        end: The ending byte offset (inclusive).\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.reader.range(data, start, end, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.range_synthetic","title":"<code>range_synthetic(data, start=0, end=None, /, **kwargs)</code>","text":"<p>Generic implementation of range operation that relies on STREAM.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to read.</p> <p> TYPE: <code>FileData</code> </p> <code>start</code> <p>The starting byte offset.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>end</code> <p>The ending byte offset (inclusive).</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def range_synthetic(\n    self, data: data.FileData, start: int = 0, end: int | None = None, /, **kwargs: Any\n) -&gt; Iterable[bytes]:\n    \"\"\"Generic implementation of range operation that relies on [STREAM][file_keeper.Capability.STREAM].\n\n    Args:\n        data: The FileData object representing the file to read.\n        start: The starting byte offset.\n        end: The ending byte offset (inclusive).\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    if end is None:\n        end = cast(int, float(\"inf\"))\n\n    end -= start\n    if end &lt;= 0:\n        return\n\n    for chunk in self.stream(data, **kwargs):\n        if start &gt; 0:\n            start -= len(chunk)\n            if start &lt; 0:\n                chunk = chunk[start:]  # noqa: PLW2901\n            else:\n                continue\n\n        yield chunk[: end and None]\n        end -= len(chunk)\n        if end &lt;= 0:\n            break\n</code></pre>"},{"location":"api/#file_keeper.Storage.remove","title":"<code>remove(data, /, **kwargs)</code>","text":"<p>Remove file from the storage.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to remove.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.REMOVE)\ndef remove(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n    \"\"\"Remove file from the storage.\n\n    Args:\n        data: The FileData object representing the file to remove.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.remove(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.resumable_refresh","title":"<code>resumable_refresh(data, /, **kwargs)</code>","text":"<p>Show details of the incomplete resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.RESUMABLE)\ndef resumable_refresh(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Show details of the incomplete resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.resumable_refresh(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.resumable_remove","title":"<code>resumable_remove(data, /, **kwargs)</code>","text":"<p>Remove incomplete resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.RESUMABLE)\ndef resumable_remove(self, data: data.FileData, /, **kwargs: Any) -&gt; bool:\n    \"\"\"Remove incomplete resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.resumable_remove(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.resumable_resume","title":"<code>resumable_resume(data, /, **kwargs)</code>","text":"<p>Resume the interrupted resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.RESUMABLE)\ndef resumable_resume(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Resume the interrupted resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.resumable_resume(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.resumable_start","title":"<code>resumable_start(data, /, **kwargs)</code>","text":"<p>Prepare everything for resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.RESUMABLE)\ndef resumable_start(self, data: data.FileData, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Prepare everything for resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.resumable_start(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.scan","title":"<code>scan(**kwargs)</code>","text":"<p>List all locations(filenames) in storage.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.SCAN)\ndef scan(self, **kwargs: Any) -&gt; Iterable[str]:\n    \"\"\"List all locations(filenames) in storage.\n\n    Args:\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.scan(kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.signed","title":"<code>signed(action, duration, location, **kwargs)</code>","text":"<p>Make an URL for signed action.</p> PARAMETER DESCRIPTION <code>action</code> <p>The action to sign (e.g., \"upload\", \"download\").</p> <p> TYPE: <code>SignedAction</code> </p> <code>duration</code> <p>The duration for which the signed URL is valid.</p> <p> TYPE: <code>int</code> </p> <code>location</code> <p>The location of the file to sign.</p> <p> TYPE: <code>Location</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.SIGNED)\ndef signed(\n    self,\n    action: types.SignedAction,\n    duration: int,\n    location: types.Location,\n    **kwargs: Any,\n) -&gt; str:\n    \"\"\"Make an URL for signed action.\n\n    Args:\n        action: The action to sign (e.g., \"upload\", \"download\").\n        duration: The duration for which the signed URL is valid.\n        location: The location of the file to sign.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.manager.signed(action, duration, location, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.stream","title":"<code>stream(data, /, **kwargs)</code>","text":"<p>Return byte-stream of the file content.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to stream.</p> <p> TYPE: <code>FileData</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.STREAM)\ndef stream(self, data: data.FileData, /, **kwargs: Any) -&gt; Iterable[bytes]:\n    \"\"\"Return byte-stream of the file content.\n\n    Args:\n        data: The FileData object representing the file to stream.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    return self.reader.stream(data, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.supports","title":"<code>supports(operation)</code>","text":"<p>Check whether the storage supports operation.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def supports(self, operation: Capability) -&gt; bool:\n    \"\"\"Check whether the storage supports operation.\"\"\"\n    return self.capabilities.can(operation)\n</code></pre>"},{"location":"api/#file_keeper.Storage.supports_synthetic","title":"<code>supports_synthetic(operation, dest)</code>","text":"<p>Check if the storage can emulate operation using other operations.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def supports_synthetic(self, operation: Capability, dest: Storage) -&gt; bool:\n    \"\"\"Check if the storage can emulate operation using other operations.\"\"\"\n    if operation is Capability.RANGE:\n        return self.supports(Capability.STREAM)\n\n    if operation is Capability.COPY:\n        return self.supports(Capability.STREAM) and dest.supports(\n            Capability.CREATE,\n        )\n\n    if operation is Capability.MOVE:\n        return self.supports(\n            Capability.STREAM | Capability.REMOVE,\n        ) and dest.supports(Capability.CREATE)\n\n    if operation is Capability.COMPOSE:\n        return self.supports(Capability.STREAM) and dest.supports(\n            Capability.CREATE | Capability.APPEND | Capability.REMOVE\n        )\n\n    return False\n</code></pre>"},{"location":"api/#file_keeper.Storage.temporal_link","title":"<code>temporal_link(data, duration, /, **kwargs)</code>","text":"<p>Return temporal download link.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file.</p> <p> TYPE: <code>FileData</code> </p> <code>duration</code> <p>The duration for which the link is valid.</p> <p> TYPE: <code>int</code> </p> <code>**kwargs</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def temporal_link(self, data: data.FileData, duration: int, /, **kwargs: Any) -&gt; str | None:\n    \"\"\"Return temporal download link.\n\n    Args:\n        data: The FileData object representing the file.\n        duration: The duration for which the link is valid.\n        **kwargs: Additional metadata for the operation.\n    \"\"\"\n    if self.supports(Capability.TEMPORAL_LINK):\n        return self.reader.temporal_link(data, duration, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Storage.upload","title":"<code>upload(location, upload, /, **kwargs)</code>","text":"<p>Upload file using single stream.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the upload.</p> <p> TYPE: <code>Location</code> </p> <code>upload</code> <p>The Upload object containing the file data.</p> <p> TYPE: <code>Upload</code> </p> <code>**kwargs</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@requires_capability(Capability.CREATE)\ndef upload(self, location: types.Location, upload: Upload, /, **kwargs: Any) -&gt; data.FileData:\n    \"\"\"Upload file using single stream.\n\n    Args:\n        location: The destination location for the upload.\n        upload: The Upload object containing the file data.\n        **kwargs: Additional metadata for the upload.\n    \"\"\"\n    return self.uploader.upload(location, upload, kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Capability","title":"<code>Capability</code>","text":"<p>               Bases: <code>Flag</code></p> <p>Enumeration of operations supported by the storage.</p> Example <pre><code>read_and_write = Capability.STREAM | Capability.CREATE\nif storage.supports(read_and_write)\n    ...\n</code></pre> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>class Capability(enum.Flag):\n    \"\"\"Enumeration of operations supported by the storage.\n\n    Example:\n        ```python\n        read_and_write = Capability.STREAM | Capability.CREATE\n        if storage.supports(read_and_write)\n            ...\n        ```\n    \"\"\"\n\n    NONE = 0\n\n    ANALYZE = enum.auto()\n    \"\"\"Return file details from the storage\"\"\"\n\n    APPEND = enum.auto()\n    \"\"\"Add content to the existing file\"\"\"\n\n    COMPOSE = enum.auto()\n    \"\"\"Combine multiple files into a new one in the same storage\"\"\"\n\n    COPY = enum.auto()\n    \"\"\"Make a copy of the file inside the same storage\"\"\"\n\n    CREATE = enum.auto()\n    \"\"\"Create a file as an atomic object\"\"\"\n\n    EXISTS = enum.auto()\n    \"\"\"Check if file exists\"\"\"\n\n    MOVE = enum.auto()\n    \"\"\"Move file to a different location inside the same storage\"\"\"\n\n    MULTIPART = enum.auto()\n    \"\"\"Create file in 3 stages: initialize, upload(repeatable), complete\"\"\"\n\n    RANGE = enum.auto()\n    \"\"\"Return specific range of bytes from the file\"\"\"\n\n    REMOVE = enum.auto()\n    \"\"\"Remove file from the storage\"\"\"\n\n    RESUMABLE = enum.auto()\n    \"\"\"Perform resumable uploads that can be continued after interruption\"\"\"\n\n    SCAN = enum.auto()\n    \"\"\"Iterate over all files in the storage\"\"\"\n\n    SIGNED = enum.auto()\n    \"\"\"Generate signed URL for specific operation\"\"\"\n\n    STREAM = enum.auto()\n    \"\"\"Return file content as stream of bytes\"\"\"\n\n    PERMANENT_LINK = enum.auto()\n    \"\"\"Make permanent download link\"\"\"\n\n    TEMPORAL_LINK = enum.auto()\n    \"\"\"Make expiring download link\"\"\"\n\n    ONE_TIME_LINK = enum.auto()\n    \"\"\"Make one-time download link\"\"\"\n\n    MANAGER_CAPABILITIES = ANALYZE | SCAN | COPY | MOVE | APPEND | COMPOSE | EXISTS | REMOVE | SIGNED\n    READER_CAPABILITIES = RANGE | STREAM | PERMANENT_LINK | TEMPORAL_LINK | ONE_TIME_LINK\n    UPLOADER_CAPABILITIES = CREATE | MULTIPART | RESUMABLE\n\n    def exclude(self, *capabilities: Capability):\n        \"\"\"Remove capabilities from the cluster.\n\n        Other Args:\n            capabilities: removed capabilities\n\n        Example:\n            ```python\n            cluster = cluster.exclude(Capability.REMOVE)\n            ```\n        \"\"\"\n        result = Capability(self)\n        for capability in capabilities:\n            result = result &amp; ~capability\n        return result\n\n    def can(self, operation: Capability) -&gt; bool:\n        return (self &amp; operation) == operation\n</code></pre>"},{"location":"api/#file_keeper.Capability.ANALYZE","title":"<code>ANALYZE = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Return file details from the storage</p>"},{"location":"api/#file_keeper.Capability.APPEND","title":"<code>APPEND = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Add content to the existing file</p>"},{"location":"api/#file_keeper.Capability.COMPOSE","title":"<code>COMPOSE = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Combine multiple files into a new one in the same storage</p>"},{"location":"api/#file_keeper.Capability.COPY","title":"<code>COPY = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Make a copy of the file inside the same storage</p>"},{"location":"api/#file_keeper.Capability.CREATE","title":"<code>CREATE = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Create a file as an atomic object</p>"},{"location":"api/#file_keeper.Capability.EXISTS","title":"<code>EXISTS = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Check if file exists</p>"},{"location":"api/#file_keeper.Capability.MOVE","title":"<code>MOVE = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Move file to a different location inside the same storage</p>"},{"location":"api/#file_keeper.Capability.MULTIPART","title":"<code>MULTIPART = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Create file in 3 stages: initialize, upload(repeatable), complete</p>"},{"location":"api/#file_keeper.Capability.ONE_TIME_LINK","title":"<code>ONE_TIME_LINK = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Make one-time download link</p>"},{"location":"api/#file_keeper.Capability.PERMANENT_LINK","title":"<code>PERMANENT_LINK = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Make permanent download link</p>"},{"location":"api/#file_keeper.Capability.RANGE","title":"<code>RANGE = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Return specific range of bytes from the file</p>"},{"location":"api/#file_keeper.Capability.REMOVE","title":"<code>REMOVE = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Remove file from the storage</p>"},{"location":"api/#file_keeper.Capability.RESUMABLE","title":"<code>RESUMABLE = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Perform resumable uploads that can be continued after interruption</p>"},{"location":"api/#file_keeper.Capability.SCAN","title":"<code>SCAN = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Iterate over all files in the storage</p>"},{"location":"api/#file_keeper.Capability.SIGNED","title":"<code>SIGNED = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Generate signed URL for specific operation</p>"},{"location":"api/#file_keeper.Capability.STREAM","title":"<code>STREAM = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Return file content as stream of bytes</p>"},{"location":"api/#file_keeper.Capability.TEMPORAL_LINK","title":"<code>TEMPORAL_LINK = enum.auto()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Make expiring download link</p>"},{"location":"api/#file_keeper.Capability.exclude","title":"<code>exclude(*capabilities)</code>","text":"<p>Remove capabilities from the cluster.</p> PARAMETER DESCRIPTION <code>capabilities</code> <p>removed capabilities</p> <p> TYPE: <code>Capability</code> </p> Example <pre><code>cluster = cluster.exclude(Capability.REMOVE)\n</code></pre> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>def exclude(self, *capabilities: Capability):\n    \"\"\"Remove capabilities from the cluster.\n\n    Other Args:\n        capabilities: removed capabilities\n\n    Example:\n        ```python\n        cluster = cluster.exclude(Capability.REMOVE)\n        ```\n    \"\"\"\n    result = Capability(self)\n    for capability in capabilities:\n        result = result &amp; ~capability\n    return result\n</code></pre>"},{"location":"api/#file_keeper.Settings","title":"<code>Settings</code>  <code>dataclass</code>","text":"<p>Settings for the storage adapter.</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@dataclasses.dataclass()\nclass Settings:\n    \"\"\"Settings for the storage adapter.\"\"\"\n\n    name: str = \"unknown\"\n    \"\"\"Descriptive name of the storage used for debugging.\"\"\"\n\n    override_existing: bool = False\n    \"\"\"If file already exists, replace it with new content.\"\"\"\n\n    path: str = \"\"\n    \"\"\"Prefix for the file's location.\"\"\"\n\n    location_transformers: list[str] = cast(\"list[str]\", dataclasses.field(default_factory=list))\n    \"\"\"List of transformations applied to the file location.\"\"\"\n\n    disabled_capabilities: list[str] = cast(\"list[str]\", dataclasses.field(default_factory=list))\n    \"\"\"Capabilities that are not supported even if implemented.\"\"\"\n\n    initialize: bool = False\n    \"\"\"Prepare storage backend for uploads(create path, bucket, DB)\"\"\"\n\n    _required_options: ClassVar[list[str]] = []\n    _extra_settings: dict[str, Any] = cast(\"dict[str, Any]\", dataclasses.field(default_factory=dict))\n\n    def __post_init__(self, **kwargs: Any):\n        for attr in self._required_options:\n            if not getattr(self, attr):\n                raise exceptions.MissingStorageConfigurationError(self.name, attr)\n\n    @classmethod\n    def from_dict(cls, data: Mapping[str, Any]) -&gt; Settings:\n        \"\"\"Make settings object using dictionary as a source.\n\n        Any unexpected options are extracted from the `data` to avoid\n        initialization errors from dataclass constructor.\n\n        Args:\n            data: mapping with settings\n\n        Returns:\n            settings object built from data\n\n        \"\"\"\n        # try:\n        #     return cls(**settings)\n        # except TypeError as err:\n        #     raise exceptions.InvalidStorageConfigurationError(\n        #         settings.get(\"name\") or cls, str(err)\n        #     ) from err\n\n        sig = inspect.signature(cls)\n        names = set(sig.parameters)\n\n        valid = {}\n        invalid = {}\n        for k, v in data.items():\n            if k in names:\n                valid[k] = v\n            else:\n                invalid[k] = v\n\n        valid.setdefault(\"_extra_settings\", {}).update(invalid)\n        cfg = cls(**valid)\n        if invalid:\n            log.warning(\n                \"Storage %s received unknow settings: %s\",\n                cfg.name,\n                invalid,\n            )\n        return cfg\n</code></pre>"},{"location":"api/#file_keeper.Settings.disabled_capabilities","title":"<code>disabled_capabilities = cast('list[str]', dataclasses.field(default_factory=list))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Capabilities that are not supported even if implemented.</p>"},{"location":"api/#file_keeper.Settings.initialize","title":"<code>initialize = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Prepare storage backend for uploads(create path, bucket, DB)</p>"},{"location":"api/#file_keeper.Settings.location_transformers","title":"<code>location_transformers = cast('list[str]', dataclasses.field(default_factory=list))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of transformations applied to the file location.</p>"},{"location":"api/#file_keeper.Settings.name","title":"<code>name = 'unknown'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Descriptive name of the storage used for debugging.</p>"},{"location":"api/#file_keeper.Settings.override_existing","title":"<code>override_existing = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If file already exists, replace it with new content.</p>"},{"location":"api/#file_keeper.Settings.path","title":"<code>path = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Prefix for the file's location.</p>"},{"location":"api/#file_keeper.Settings.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Make settings object using dictionary as a source.</p> <p>Any unexpected options are extracted from the <code>data</code> to avoid initialization errors from dataclass constructor.</p> PARAMETER DESCRIPTION <code>data</code> <p>mapping with settings</p> <p> TYPE: <code>Mapping[str, Any]</code> </p> RETURNS DESCRIPTION <code>Settings</code> <p>settings object built from data</p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Mapping[str, Any]) -&gt; Settings:\n    \"\"\"Make settings object using dictionary as a source.\n\n    Any unexpected options are extracted from the `data` to avoid\n    initialization errors from dataclass constructor.\n\n    Args:\n        data: mapping with settings\n\n    Returns:\n        settings object built from data\n\n    \"\"\"\n    # try:\n    #     return cls(**settings)\n    # except TypeError as err:\n    #     raise exceptions.InvalidStorageConfigurationError(\n    #         settings.get(\"name\") or cls, str(err)\n    #     ) from err\n\n    sig = inspect.signature(cls)\n    names = set(sig.parameters)\n\n    valid = {}\n    invalid = {}\n    for k, v in data.items():\n        if k in names:\n            valid[k] = v\n        else:\n            invalid[k] = v\n\n    valid.setdefault(\"_extra_settings\", {}).update(invalid)\n    cfg = cls(**valid)\n    if invalid:\n        log.warning(\n            \"Storage %s received unknow settings: %s\",\n            cfg.name,\n            invalid,\n        )\n    return cfg\n</code></pre>"},{"location":"api/#file_keeper.Uploader","title":"<code>Uploader</code>","text":"<p>               Bases: <code>StorageService</code></p> <p>Service responsible for writing data into a storage.</p> <p><code>Storage</code> internally calls methods of this service. For example, <code>Storage.upload(location, upload, **kwargs)</code> results in <code>Uploader.upload(location, upload, kwargs)</code>.</p> Example <pre><code>class MyUploader(Uploader):\n    def upload(\n        self, location: types.Location, upload: Upload, extras: dict[str, Any]\n    ) -&gt; FileData:\n        reader = upload.hashing_reader()\n\n        with open(location, \"wb\") as dest:\n            dest.write(reader.read())\n\n        return FileData(\n            location, upload.size,\n            upload.content_type,\n            reader.get_hash()\n        )\n</code></pre> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>class Uploader(StorageService):\n    \"\"\"Service responsible for writing data into a storage.\n\n    `Storage` internally calls methods of this service. For example,\n    `Storage.upload(location, upload, **kwargs)` results in\n    `Uploader.upload(location, upload, kwargs)`.\n\n    Example:\n        ```python\n        class MyUploader(Uploader):\n            def upload(\n                self, location: types.Location, upload: Upload, extras: dict[str, Any]\n            ) -&gt; FileData:\n                reader = upload.hashing_reader()\n\n                with open(location, \"wb\") as dest:\n                    dest.write(reader.read())\n\n                return FileData(\n                    location, upload.size,\n                    upload.content_type,\n                    reader.get_hash()\n                )\n        ```\n    \"\"\"\n\n    def upload(self, location: types.Location, upload: Upload, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Upload file using single stream.\n\n        Args:\n            location: The destination location for the upload.\n            upload: The Upload object containing the file data.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def resumable_start(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Prepare everything for resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def resumable_refresh(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Show details of the incomplete resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def resumable_resume(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Resume the interrupted resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def resumable_remove(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n        \"\"\"Remove incomplete resumable upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def multipart_start(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Prepare everything for multipart(resumable) upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def multipart_refresh(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Show details of the incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def multipart_update(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Add data to the incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def multipart_complete(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Verify file integrity and finalize incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n\n    def multipart_remove(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n        \"\"\"Interrupt and remove incomplete upload.\n\n        Args:\n            data: The FileData object containing the upload metadata.\n            extras: Additional metadata for the upload.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.multipart_complete","title":"<code>multipart_complete(data, extras)</code>","text":"<p>Verify file integrity and finalize incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def multipart_complete(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Verify file integrity and finalize incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.multipart_refresh","title":"<code>multipart_refresh(data, extras)</code>","text":"<p>Show details of the incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def multipart_refresh(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Show details of the incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.multipart_remove","title":"<code>multipart_remove(data, extras)</code>","text":"<p>Interrupt and remove incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def multipart_remove(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n    \"\"\"Interrupt and remove incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.multipart_start","title":"<code>multipart_start(data, extras)</code>","text":"<p>Prepare everything for multipart(resumable) upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def multipart_start(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Prepare everything for multipart(resumable) upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.multipart_update","title":"<code>multipart_update(data, extras)</code>","text":"<p>Add data to the incomplete upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def multipart_update(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Add data to the incomplete upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.resumable_refresh","title":"<code>resumable_refresh(data, extras)</code>","text":"<p>Show details of the incomplete resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def resumable_refresh(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Show details of the incomplete resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.resumable_remove","title":"<code>resumable_remove(data, extras)</code>","text":"<p>Remove incomplete resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def resumable_remove(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n    \"\"\"Remove incomplete resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.resumable_resume","title":"<code>resumable_resume(data, extras)</code>","text":"<p>Resume the interrupted resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def resumable_resume(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Resume the interrupted resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.resumable_start","title":"<code>resumable_start(data, extras)</code>","text":"<p>Prepare everything for resumable upload.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object containing the upload metadata.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def resumable_start(self, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Prepare everything for resumable upload.\n\n    Args:\n        data: The FileData object containing the upload metadata.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Uploader.upload","title":"<code>upload(location, upload, extras)</code>","text":"<p>Upload file using single stream.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the upload.</p> <p> TYPE: <code>Location</code> </p> <code>upload</code> <p>The Upload object containing the file data.</p> <p> TYPE: <code>Upload</code> </p> <code>extras</code> <p>Additional metadata for the upload.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def upload(self, location: types.Location, upload: Upload, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Upload file using single stream.\n\n    Args:\n        location: The destination location for the upload.\n        upload: The Upload object containing the file data.\n        extras: Additional metadata for the upload.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager","title":"<code>Manager</code>","text":"<p>               Bases: <code>StorageService</code></p> <p>Service responsible for maintenance file operations.</p> <p><code>Storage</code> internally calls methods of this service. For example, <code>Storage.remove(data, **kwargs)</code> results in <code>Manager.remove(data, kwargs)</code>.</p> Example <pre><code>class MyManager(Manager):\n    def remove(\n        self, data: FileData|FileData, extras: dict[str, Any]\n    ) -&gt; bool:\n        os.remove(data.location)\n        return True\n</code></pre> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>class Manager(StorageService):\n    \"\"\"Service responsible for maintenance file operations.\n\n    `Storage` internally calls methods of this service. For example,\n    `Storage.remove(data, **kwargs)` results in `Manager.remove(data, kwargs)`.\n\n    Example:\n        ```python\n        class MyManager(Manager):\n            def remove(\n                self, data: FileData|FileData, extras: dict[str, Any]\n            ) -&gt; bool:\n                os.remove(data.location)\n                return True\n        ```\n    \"\"\"\n\n    def remove(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n        \"\"\"Remove file from the storage.\n\n        Args:\n            data: The FileData object representing the file to remove.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def exists(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n        \"\"\"Check if file exists in the storage.\n\n        Args:\n            data: The FileData object representing the file to check.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def compose(\n        self, location: types.Location, datas: Iterable[data.FileData], extras: dict[str, Any]\n    ) -&gt; data.FileData:\n        \"\"\"Combine multipe file inside the storage into a new one.\n\n        Args:\n            location: The destination location for the composed file.\n            datas: An iterable of FileData objects representing the files to combine.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def append(self, data: data.FileData, upload: Upload, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Append content to existing file.\n\n        Args:\n            data: The FileData object representing the file to append to.\n            upload: The Upload object containing the content to append.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def copy(self, location: types.Location, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Copy file inside the storage.\n\n        Args:\n            location: The destination location for the copied file.\n            data: The FileData object representing the file to copy.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def move(self, location: types.Location, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Move file to a different location inside the storage.\n\n        Args:\n            location: The destination location for the moved file.\n            data: The FileData object representing the file to move.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def scan(self, extras: dict[str, Any]) -&gt; Iterable[str]:\n        \"\"\"List all locations(filenames) in storage.\n\n        Args:\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def analyze(self, location: types.Location, extras: dict[str, Any]) -&gt; data.FileData:\n        \"\"\"Return details about location.\n\n        Args:\n            location: The location of the file to analyze.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def signed(\n        self, action: types.SignedAction, duration: int, location: types.Location, extras: dict[str, Any]\n    ) -&gt; str:\n        \"\"\"Make an URL for signed action.\n\n        Args:\n            action: The action to sign (e.g., \"upload\", \"download\").\n            duration: The duration for which the signed URL is valid.\n            location: The location of the file to sign.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.analyze","title":"<code>analyze(location, extras)</code>","text":"<p>Return details about location.</p> PARAMETER DESCRIPTION <code>location</code> <p>The location of the file to analyze.</p> <p> TYPE: <code>Location</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def analyze(self, location: types.Location, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Return details about location.\n\n    Args:\n        location: The location of the file to analyze.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.append","title":"<code>append(data, upload, extras)</code>","text":"<p>Append content to existing file.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to append to.</p> <p> TYPE: <code>FileData</code> </p> <code>upload</code> <p>The Upload object containing the content to append.</p> <p> TYPE: <code>Upload</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def append(self, data: data.FileData, upload: Upload, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Append content to existing file.\n\n    Args:\n        data: The FileData object representing the file to append to.\n        upload: The Upload object containing the content to append.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.compose","title":"<code>compose(location, datas, extras)</code>","text":"<p>Combine multipe file inside the storage into a new one.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the composed file.</p> <p> TYPE: <code>Location</code> </p> <code>datas</code> <p>An iterable of FileData objects representing the files to combine.</p> <p> TYPE: <code>Iterable[FileData]</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def compose(\n    self, location: types.Location, datas: Iterable[data.FileData], extras: dict[str, Any]\n) -&gt; data.FileData:\n    \"\"\"Combine multipe file inside the storage into a new one.\n\n    Args:\n        location: The destination location for the composed file.\n        datas: An iterable of FileData objects representing the files to combine.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.copy","title":"<code>copy(location, data, extras)</code>","text":"<p>Copy file inside the storage.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the copied file.</p> <p> TYPE: <code>Location</code> </p> <code>data</code> <p>The FileData object representing the file to copy.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def copy(self, location: types.Location, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Copy file inside the storage.\n\n    Args:\n        location: The destination location for the copied file.\n        data: The FileData object representing the file to copy.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.exists","title":"<code>exists(data, extras)</code>","text":"<p>Check if file exists in the storage.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to check.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def exists(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n    \"\"\"Check if file exists in the storage.\n\n    Args:\n        data: The FileData object representing the file to check.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.move","title":"<code>move(location, data, extras)</code>","text":"<p>Move file to a different location inside the storage.</p> PARAMETER DESCRIPTION <code>location</code> <p>The destination location for the moved file.</p> <p> TYPE: <code>Location</code> </p> <code>data</code> <p>The FileData object representing the file to move.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def move(self, location: types.Location, data: data.FileData, extras: dict[str, Any]) -&gt; data.FileData:\n    \"\"\"Move file to a different location inside the storage.\n\n    Args:\n        location: The destination location for the moved file.\n        data: The FileData object representing the file to move.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.remove","title":"<code>remove(data, extras)</code>","text":"<p>Remove file from the storage.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to remove.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def remove(self, data: data.FileData, extras: dict[str, Any]) -&gt; bool:\n    \"\"\"Remove file from the storage.\n\n    Args:\n        data: The FileData object representing the file to remove.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.scan","title":"<code>scan(extras)</code>","text":"<p>List all locations(filenames) in storage.</p> PARAMETER DESCRIPTION <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def scan(self, extras: dict[str, Any]) -&gt; Iterable[str]:\n    \"\"\"List all locations(filenames) in storage.\n\n    Args:\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Manager.signed","title":"<code>signed(action, duration, location, extras)</code>","text":"<p>Make an URL for signed action.</p> PARAMETER DESCRIPTION <code>action</code> <p>The action to sign (e.g., \"upload\", \"download\").</p> <p> TYPE: <code>SignedAction</code> </p> <code>duration</code> <p>The duration for which the signed URL is valid.</p> <p> TYPE: <code>int</code> </p> <code>location</code> <p>The location of the file to sign.</p> <p> TYPE: <code>Location</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def signed(\n    self, action: types.SignedAction, duration: int, location: types.Location, extras: dict[str, Any]\n) -&gt; str:\n    \"\"\"Make an URL for signed action.\n\n    Args:\n        action: The action to sign (e.g., \"upload\", \"download\").\n        duration: The duration for which the signed URL is valid.\n        location: The location of the file to sign.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Reader","title":"<code>Reader</code>","text":"<p>               Bases: <code>StorageService</code></p> <p>Service responsible for reading data from the storage.</p> <p><code>Storage</code> internally calls methods of this service. For example, <code>Storage.stream(data, **kwargs)</code> results in <code>Reader.stream(data, kwargs)</code>.</p> Example <pre><code>class MyReader(Reader):\n    def stream(\n        self, data: data.FileData, extras: dict[str, Any]\n    ) -&gt; Iterable[bytes]:\n        return open(data.location, \"rb\")\n</code></pre> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>class Reader(StorageService):\n    \"\"\"Service responsible for reading data from the storage.\n\n    `Storage` internally calls methods of this service. For example,\n    `Storage.stream(data, **kwargs)` results in `Reader.stream(data, kwargs)`.\n\n    Example:\n        ```python\n        class MyReader(Reader):\n            def stream(\n                self, data: data.FileData, extras: dict[str, Any]\n            ) -&gt; Iterable[bytes]:\n                return open(data.location, \"rb\")\n        ```\n    \"\"\"\n\n    def stream(self, data: data.FileData, extras: dict[str, Any]) -&gt; Iterable[bytes]:\n        \"\"\"Return byte-stream of the file content.\n\n        Args:\n            data: The FileData object representing the file to stream.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def content(self, data: data.FileData, extras: dict[str, Any]) -&gt; bytes:\n        \"\"\"Return file content as a single byte object.\n\n        Args:\n            data: The FileData object representing the file to read.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        return b\"\".join(self.stream(data, extras))\n\n    def range(self, data: data.FileData, start: int, end: int | None, extras: dict[str, Any]) -&gt; Iterable[bytes]:\n        \"\"\"Return slice of the file content.\n\n        Args:\n            data: The FileData object representing the file to read.\n            start: The starting byte offset.\n            end: The ending byte offset (inclusive).\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def permanent_link(self, data: data.FileData, extras: dict[str, Any]) -&gt; str:\n        \"\"\"Return permanent download link.\n\n        Args:\n            data: The FileData object representing the file.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def temporal_link(self, data: data.FileData, duration: int, extras: dict[str, Any]) -&gt; str:\n        \"\"\"Return temporal download link.\n\n        Args:\n            data: The FileData object representing the file.\n            duration: The duration for which the link is valid.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def one_time_link(self, data: data.FileData, extras: dict[str, Any]) -&gt; str:\n        \"\"\"Return one-time download link.\n\n        Args:\n            data: The FileData object representing the file.\n            extras: Additional metadata for the operation.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Reader.content","title":"<code>content(data, extras)</code>","text":"<p>Return file content as a single byte object.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to read.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def content(self, data: data.FileData, extras: dict[str, Any]) -&gt; bytes:\n    \"\"\"Return file content as a single byte object.\n\n    Args:\n        data: The FileData object representing the file to read.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    return b\"\".join(self.stream(data, extras))\n</code></pre>"},{"location":"api/#file_keeper.Reader.one_time_link","title":"<code>one_time_link(data, extras)</code>","text":"<p>Return one-time download link.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def one_time_link(self, data: data.FileData, extras: dict[str, Any]) -&gt; str:\n    \"\"\"Return one-time download link.\n\n    Args:\n        data: The FileData object representing the file.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Reader.permanent_link","title":"<code>permanent_link(data, extras)</code>","text":"<p>Return permanent download link.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def permanent_link(self, data: data.FileData, extras: dict[str, Any]) -&gt; str:\n    \"\"\"Return permanent download link.\n\n    Args:\n        data: The FileData object representing the file.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Reader.range","title":"<code>range(data, start, end, extras)</code>","text":"<p>Return slice of the file content.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to read.</p> <p> TYPE: <code>FileData</code> </p> <code>start</code> <p>The starting byte offset.</p> <p> TYPE: <code>int</code> </p> <code>end</code> <p>The ending byte offset (inclusive).</p> <p> TYPE: <code>int | None</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def range(self, data: data.FileData, start: int, end: int | None, extras: dict[str, Any]) -&gt; Iterable[bytes]:\n    \"\"\"Return slice of the file content.\n\n    Args:\n        data: The FileData object representing the file to read.\n        start: The starting byte offset.\n        end: The ending byte offset (inclusive).\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Reader.stream","title":"<code>stream(data, extras)</code>","text":"<p>Return byte-stream of the file content.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file to stream.</p> <p> TYPE: <code>FileData</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def stream(self, data: data.FileData, extras: dict[str, Any]) -&gt; Iterable[bytes]:\n    \"\"\"Return byte-stream of the file content.\n\n    Args:\n        data: The FileData object representing the file to stream.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.Reader.temporal_link","title":"<code>temporal_link(data, duration, extras)</code>","text":"<p>Return temporal download link.</p> PARAMETER DESCRIPTION <code>data</code> <p>The FileData object representing the file.</p> <p> TYPE: <code>FileData</code> </p> <code>duration</code> <p>The duration for which the link is valid.</p> <p> TYPE: <code>int</code> </p> <code>extras</code> <p>Additional metadata for the operation.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/file_keeper/core/storage.py</code> <pre><code>def temporal_link(self, data: data.FileData, duration: int, extras: dict[str, Any]) -&gt; str:\n    \"\"\"Return temporal download link.\n\n    Args:\n        data: The FileData object representing the file.\n        duration: The duration for which the link is valid.\n        extras: Additional metadata for the operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#file_keeper.FileData","title":"<code>FileData</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseData[TData]</code></p> <p>Information required by storage to operate the file.</p> PARAMETER DESCRIPTION <code>location</code> <p>filepath, filename or any other type of unique identifier</p> <p> TYPE: <code>Location</code> </p> <code>size</code> <p>size of the file in bytes</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>content_type</code> <p>MIMEtype of the file</p> <p> TYPE: <code>str</code> DEFAULT: <code>'application/octet-stream'</code> </p> <code>hash</code> <p>checksum of the file</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>storage_data</code> <p>additional details set by storage adapter</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>cast('dict[str, Any]', field(default_factory=dict))</code> </p> Example <pre><code>FileData(\n    \"local/path.txt\",\n    123,\n    \"text/plain\",\n    md5_of_content,\n)\n</code></pre> Source code in <code>src/file_keeper/core/data.py</code> <pre><code>@dataclasses.dataclass(frozen=True)\nclass FileData(BaseData[TData]):\n    \"\"\"Information required by storage to operate the file.\n\n    Args:\n        location: filepath, filename or any other type of unique identifier\n        size: size of the file in bytes\n        content_type: MIMEtype of the file\n        hash: checksum of the file\n        storage_data: additional details set by storage adapter\n\n    Example:\n        ```\n        FileData(\n            \"local/path.txt\",\n            123,\n            \"text/plain\",\n            md5_of_content,\n        )\n        ```\n    \"\"\"\n\n    content_type: str = \"application/octet-stream\"\n</code></pre>"},{"location":"api/#file_keeper.Upload","title":"<code>Upload</code>  <code>dataclass</code>","text":"<p>Standard upload details.</p> PARAMETER DESCRIPTION <code>stream</code> <p>iterable of bytes or file-like object</p> <p> TYPE: <code>PStream</code> </p> <code>filename</code> <p>name of the file</p> <p> TYPE: <code>str</code> </p> <code>size</code> <p>size of the file in bytes</p> <p> TYPE: <code>int</code> </p> <code>content_type</code> <p>MIMEtype of the file</p> <p> TYPE: <code>str</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Upload(\n&gt;&gt;&gt;     BytesIO(b\"hello world\"),\n&gt;&gt;&gt;     \"file.txt\",\n&gt;&gt;&gt;     11,\n&gt;&gt;&gt;     \"text/plain\",\n&gt;&gt;&gt; )\n</code></pre> Source code in <code>src/file_keeper/core/upload.py</code> <pre><code>@dataclasses.dataclass\nclass Upload:\n    \"\"\"Standard upload details.\n\n    Args:\n        stream: iterable of bytes or file-like object\n        filename: name of the file\n        size: size of the file in bytes\n        content_type: MIMEtype of the file\n\n    Examples:\n        &gt;&gt;&gt; Upload(\n        &gt;&gt;&gt;     BytesIO(b\"hello world\"),\n        &gt;&gt;&gt;     \"file.txt\",\n        &gt;&gt;&gt;     11,\n        &gt;&gt;&gt;     \"text/plain\",\n        &gt;&gt;&gt; )\n    \"\"\"\n\n    stream: types.PStream\n    \"\"\"Content as iterable of bytes\"\"\"\n    filename: str\n    \"\"\"Name of the file\"\"\"\n    size: int\n    \"\"\"Size of the file\"\"\"\n    content_type: str\n    \"\"\"MIME Type of the file\"\"\"\n\n    @property\n    def seekable_stream(self) -&gt; types.PSeekableStream | None:\n        \"\"\"Return stream that can be rewinded after reading.\n\n        If internal stream does not support file-like `seek`, nothing is\n        returned from this property.\n\n        Use this property if you want to read the file ahead, to get CSV column\n        names, list of files inside ZIP, EXIF metadata. If you get `None` from\n        it, stream does not support seeking and you won't be able to rewind\n        cursor to the beginning of the file after reading something.\n\n        Example:\n            ```python\n            upload = make_upload(...)\n            if fd := upload.seekable_stream():\n                # read fragment of the file\n                chunk = fd.read(1024)\n                # move cursor to the end of the stream\n                fd.seek(0, 2)\n                # position of the cursor is the same as number of bytes in stream\n                size = fd.tell()\n                # move cursor back, because you don't want to accidentally loose\n                # any bites from the beginning of stream when uploader reads from it\n                fd.seek(0)\n            ```\n\n        Returns:\n            file-like stream or nothing\n\n        \"\"\"\n        if hasattr(self.stream, \"tell\") and hasattr(self.stream, \"seek\"):\n            return cast(types.PSeekableStream, self.stream)\n\n        return None\n\n    def hashing_reader(self, **kwargs: Any) -&gt; utils.HashingReader:\n        return utils.HashingReader(self.stream, **kwargs)\n</code></pre>"},{"location":"api/#file_keeper.Upload.content_type","title":"<code>content_type</code>  <code>instance-attribute</code>","text":"<p>MIME Type of the file</p>"},{"location":"api/#file_keeper.Upload.filename","title":"<code>filename</code>  <code>instance-attribute</code>","text":"<p>Name of the file</p>"},{"location":"api/#file_keeper.Upload.seekable_stream","title":"<code>seekable_stream</code>  <code>property</code>","text":"<p>Return stream that can be rewinded after reading.</p> <p>If internal stream does not support file-like <code>seek</code>, nothing is returned from this property.</p> <p>Use this property if you want to read the file ahead, to get CSV column names, list of files inside ZIP, EXIF metadata. If you get <code>None</code> from it, stream does not support seeking and you won't be able to rewind cursor to the beginning of the file after reading something.</p> Example <pre><code>upload = make_upload(...)\nif fd := upload.seekable_stream():\n    # read fragment of the file\n    chunk = fd.read(1024)\n    # move cursor to the end of the stream\n    fd.seek(0, 2)\n    # position of the cursor is the same as number of bytes in stream\n    size = fd.tell()\n    # move cursor back, because you don't want to accidentally loose\n    # any bites from the beginning of stream when uploader reads from it\n    fd.seek(0)\n</code></pre> RETURNS DESCRIPTION <code>PSeekableStream | None</code> <p>file-like stream or nothing</p>"},{"location":"api/#file_keeper.Upload.size","title":"<code>size</code>  <code>instance-attribute</code>","text":"<p>Size of the file</p>"},{"location":"api/#file_keeper.Upload.stream","title":"<code>stream</code>  <code>instance-attribute</code>","text":"<p>Content as iterable of bytes</p>"},{"location":"api/#file_keeper.Location","title":"<code>Location = NewType('Location', str)</code>  <code>module-attribute</code>","text":""},{"location":"api/#file_keeper.SignedAction","title":"<code>SignedAction = Literal['upload', 'download', 'delete']</code>  <code>module-attribute</code>","text":""},{"location":"api/#file_keeper.HashingReader","title":"<code>HashingReader</code>","text":"<p>IO stream wrapper that computes content hash while stream is consumed.</p> PARAMETER DESCRIPTION <code>stream</code> <p>iterable of bytes or file-like object</p> <p> TYPE: <code>PStream</code> </p> <code>chunk_size</code> <p>max number of bytes read at once</p> <p> TYPE: <code>int</code> DEFAULT: <code>CHUNK_SIZE</code> </p> <code>algorithm</code> <p>hashing algorithm</p> <p> TYPE: <code>str</code> DEFAULT: <code>'md5'</code> </p> Example <pre><code>reader = HashingReader(readable_stream)\nfor chunk in reader:\n    ...\nprint(f\"Hash: {reader.get_hash()}\")\n</code></pre> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>class HashingReader:\n    \"\"\"IO stream wrapper that computes content hash while stream is consumed.\n\n    Args:\n        stream: iterable of bytes or file-like object\n        chunk_size: max number of bytes read at once\n        algorithm: hashing algorithm\n\n    Example:\n        ```\n        reader = HashingReader(readable_stream)\n        for chunk in reader:\n            ...\n        print(f\"Hash: {reader.get_hash()}\")\n        ```\n    \"\"\"\n\n    stream: types.PStream\n    chunk_size: int\n    algorithm: str\n    hashsum: Any\n    position: int\n\n    def __init__(\n        self,\n        stream: types.PStream,\n        chunk_size: int = CHUNK_SIZE,\n        algorithm: str = \"md5\",\n    ):\n        self.stream = stream\n        self.chunk_size = chunk_size\n        self.algorithm = algorithm\n        self.hashsum = hashlib.new(algorithm)\n        self.position = 0\n\n    def __iter__(self) -&gt; Iterator[bytes]:\n        return self\n\n    def __next__(self) -&gt; bytes:\n        chunk = self.stream.read(self.chunk_size)\n        if not chunk:\n            raise StopIteration\n\n        self.position += len(chunk)\n        self.hashsum.update(chunk)\n        return chunk\n\n    next: Callable[..., bytes] = __next__\n\n    def read(self) -&gt; bytes:\n        \"\"\"Read and return all bytes from stream at once.\"\"\"\n        return b\"\".join(self)\n\n    def get_hash(self):\n        \"\"\"Get current content hash as a string.\"\"\"\n        return self.hashsum.hexdigest()\n\n    def exhaust(self):\n        \"\"\"Exhaust internal stream to compute final version of content hash.\n\n        Note, this method does not returns data from the stream. The content\n        will be irreversibly lost after method execution.\n        \"\"\"\n        for _ in self:\n            pass\n</code></pre>"},{"location":"api/#file_keeper.HashingReader.exhaust","title":"<code>exhaust()</code>","text":"<p>Exhaust internal stream to compute final version of content hash.</p> <p>Note, this method does not returns data from the stream. The content will be irreversibly lost after method execution.</p> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>def exhaust(self):\n    \"\"\"Exhaust internal stream to compute final version of content hash.\n\n    Note, this method does not returns data from the stream. The content\n    will be irreversibly lost after method execution.\n    \"\"\"\n    for _ in self:\n        pass\n</code></pre>"},{"location":"api/#file_keeper.HashingReader.get_hash","title":"<code>get_hash()</code>","text":"<p>Get current content hash as a string.</p> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>def get_hash(self):\n    \"\"\"Get current content hash as a string.\"\"\"\n    return self.hashsum.hexdigest()\n</code></pre>"},{"location":"api/#file_keeper.HashingReader.read","title":"<code>read()</code>","text":"<p>Read and return all bytes from stream at once.</p> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>def read(self) -&gt; bytes:\n    \"\"\"Read and return all bytes from stream at once.\"\"\"\n    return b\"\".join(self)\n</code></pre>"},{"location":"api/#file_keeper.Registry","title":"<code>Registry</code>","text":"<p>               Bases: <code>Generic[V, K]</code></p> <p>Mutable collection of objects.</p> Example <pre><code>col = Registry()\n\ncol.register(\"one\", 1)\nassert col.get(\"one\") == 1\n\ncol.reset()\nassert col.get(\"one\") is None\n\nassert list(col) == [\"one\"]\n</code></pre> Source code in <code>src/file_keeper/core/registry.py</code> <pre><code>class Registry(Generic[V, K]):\n    \"\"\"Mutable collection of objects.\n\n    Example:\n        ```py\n        col = Registry()\n\n        col.register(\"one\", 1)\n        assert col.get(\"one\") == 1\n\n        col.reset()\n        assert col.get(\"one\") is None\n\n        assert list(col) == [\"one\"]\n        ```\n    \"\"\"\n\n    members: MutableMapping[K, V]\n    collector: Callable[[], Mapping[K, V]] | None\n\n    def __init__(\n        self,\n        members: dict[K, V] | None = None,\n        collector: Callable[[], Mapping[K, V]] | None = None,\n    ):\n        if members is None:\n            members = {}\n        self.members = members\n        self.collector = collector\n\n    def __len__(self):\n        return len(self.members)\n\n    def __bool__(self):\n        return bool(self.members)\n\n    def __iter__(self):\n        return iter(self.members)\n\n    def __getitem__(self, key: K):\n        return self.members[key]\n\n    def __contains__(self, item: K):\n        return item in self.members\n\n    def collect(self):\n        if self.collector:\n            self.members.update(self.collector())\n\n    def reset(self):\n        \"\"\"Remove all members from registry.\"\"\"\n        self.members.clear()\n\n    def register(self, key: K, member: V):\n        \"\"\"Add a member to registry.\"\"\"\n        self.members[key] = member\n\n    def get(self, key: K) -&gt; V | None:\n        \"\"\"Get the optional member from registry.\"\"\"\n        return self.members.get(key)\n\n    def pop(self, key: K) -&gt; V | None:\n        \"\"\"Remove the member from registry.\"\"\"\n        return self.members.pop(key, None)\n\n    def decorated(self, key: K):\n        def decorator(value: V):\n            self.register(key, value)\n            return value\n\n        return decorator\n</code></pre>"},{"location":"api/#file_keeper.Registry.get","title":"<code>get(key)</code>","text":"<p>Get the optional member from registry.</p> Source code in <code>src/file_keeper/core/registry.py</code> <pre><code>def get(self, key: K) -&gt; V | None:\n    \"\"\"Get the optional member from registry.\"\"\"\n    return self.members.get(key)\n</code></pre>"},{"location":"api/#file_keeper.Registry.pop","title":"<code>pop(key)</code>","text":"<p>Remove the member from registry.</p> Source code in <code>src/file_keeper/core/registry.py</code> <pre><code>def pop(self, key: K) -&gt; V | None:\n    \"\"\"Remove the member from registry.\"\"\"\n    return self.members.pop(key, None)\n</code></pre>"},{"location":"api/#file_keeper.Registry.register","title":"<code>register(key, member)</code>","text":"<p>Add a member to registry.</p> Source code in <code>src/file_keeper/core/registry.py</code> <pre><code>def register(self, key: K, member: V):\n    \"\"\"Add a member to registry.\"\"\"\n    self.members[key] = member\n</code></pre>"},{"location":"api/#file_keeper.Registry.reset","title":"<code>reset()</code>","text":"<p>Remove all members from registry.</p> Source code in <code>src/file_keeper/core/registry.py</code> <pre><code>def reset(self):\n    \"\"\"Remove all members from registry.\"\"\"\n    self.members.clear()\n</code></pre>"},{"location":"api/#file_keeper.adapters","title":"<code>adapters = Registry['type[Storage]']()</code>  <code>module-attribute</code>","text":""},{"location":"api/#file_keeper.parse_filesize","title":"<code>parse_filesize(value)</code>","text":"<p>Transform human-readable filesize into an integer.</p> PARAMETER DESCRIPTION <code>value</code> <p>human-readable filesize</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>size cannot be parsed or uses unknown units</p> Example <pre><code>size = parse_filesize(\"10GiB\")\nassert size == 10_737_418_240\n</code></pre> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>def parse_filesize(value: str) -&gt; int:\n    \"\"\"Transform human-readable filesize into an integer.\n\n    Args:\n        value: human-readable filesize\n\n    Raises:\n        ValueError: size cannot be parsed or uses unknown units\n\n    Example:\n        ```python\n        size = parse_filesize(\"10GiB\")\n        assert size == 10_737_418_240\n        ```\n    \"\"\"\n    result = RE_FILESIZE.match(value.strip())\n    if not result:\n        raise ValueError(value)\n\n    size, unit = result.groups()\n\n    multiplier = UNITS.get(unit.lower())\n    if not multiplier:\n        raise ValueError(value)\n\n    return int(float(size) * multiplier)\n</code></pre>"},{"location":"api/#file_keeper.humanize_filesize","title":"<code>humanize_filesize(value, base=SI_BASE)</code>","text":"<p>Transform an integer into human-readable filesize.</p> PARAMETER DESCRIPTION <code>value</code> <p>size in bytes</p> <p> TYPE: <code>int | float</code> </p> <code>base</code> <p>1000 for SI(KB, MB) or 1024 for binary(KiB, MiB)</p> <p> TYPE: <code>int</code> DEFAULT: <code>SI_BASE</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>base is not recognized</p> Example <pre><code>size = humanize_filesize(10_737_418_240, base=1024)\nassert size == \"10GiB\"\nsize = humanize_filesize(10_418_240, base=1024)\nassert size == \"9.9MiB\"\n</code></pre> Source code in <code>src/file_keeper/core/utils.py</code> <pre><code>def humanize_filesize(value: int | float, base: int = SI_BASE) -&gt; str:\n    \"\"\"Transform an integer into human-readable filesize.\n\n    Args:\n        value: size in bytes\n        base: 1000 for SI(KB, MB) or 1024 for binary(KiB, MiB)\n\n    Raises:\n        ValueError: base is not recognized\n\n    Example:\n        ```python\n        size = humanize_filesize(10_737_418_240, base=1024)\n        assert size == \"10GiB\"\n        size = humanize_filesize(10_418_240, base=1024)\n        assert size == \"9.9MiB\"\n        ```\n\n    \"\"\"\n    if base == SI_BASE:\n        suffixes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\"]\n    elif base == BINARY_BASE:\n        suffixes = [\"B\", \"KiB\", \"MiB\", \"GiB\", \"TiB\", \"PiB\", \"EiB\"]\n    else:\n        raise ValueError(base)\n\n    iteration = 0\n\n    while value &gt;= base:\n        iteration += 1\n        value /= base\n\n    value = int(value * 100) / 100\n\n    num_format = \".2f\" if iteration and not value.is_integer() else \".0f\"\n\n    return f\"{value:{num_format}}{suffixes[iteration]}\"\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#unreleased","title":"[unreleased]","text":"<p>Compare with v0.0.10</p>"},{"location":"changelog/#features","title":"\ud83d\ude80 Features","text":"<ul> <li>[breaking] frozen FileData and MultipartData (cb9dbf8)</li> <li>define <code>RESUMABLE</code> capability (bab84fa)</li> <li>complete GCS adapter (db97e20)</li> <li>Azure Blob storage adapter (fb491b2)</li> <li>zip adapter (3b3f978)</li> <li>add SIGNED capability (fc5fcbb)</li> <li>Storage.full_path (7974aca)</li> <li>add generic disabled_capabilities option (c335071)</li> <li>add EXISTS, SCAN, MOVE and COPY to s3 adapter (2cb762e)</li> <li>add EXISTS and ANALYZE to libcloud adapter (12349aa)</li> <li>less strict typing rules for storage settings (247d1c6)</li> <li>remove str from exceptions (2ecd8a2)</li> <li>add memory storage (3abc218)</li> <li>storage.ext.register accepts optional <code>reset</code> parameter (c5edce8)</li> <li>Settings log extra options with debug level instead of raising an exception (7308578)</li> <li>add null storage (c1f8476)</li> </ul>"},{"location":"changelog/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>s3 unconditionally overrides files (c059f2b)</li> <li>storage settings keep a lot of intermediate parameters (cf69cf2)</li> <li>libcloud silently overrides existing objects (599f099)</li> </ul>"},{"location":"changelog/#refactor","title":"\ud83d\ude9c Refactor","text":"<ul> <li>[breaking] remove <code>location</code> from arguments of <code>multipart_start</code> (876ce46)</li> <li>[breaking] drop <code>MultipartData</code> and use <code>FileData</code> instead everywhere (c1c01c3)</li> <li>[breaking] <code>Storage.remove</code> does not accept <code>MultipartData</code>. Use <code>Storage.multipart_remove</code> instead (ce3e522)</li> <li>[breaking] <code>create_path</code> option for fs renamed to <code>initialize</code> (1329997)</li> <li>[breaking] Storage.temporal_link requires <code>duration</code> parameter (0d92777)</li> <li>[breaking] Storage.stream_as_upload renamed to file_as_upload (29ec68b)</li> <li>[breaking] fs and opendal settings no longer have recursive flag (3f6e29b)</li> <li>redis uses <code>bucket</code> option instead of <code>path</code> (966241f)</li> <li>remove pytz dependency (43079ea)</li> <li>rename redis_url to url in redis settings (2c998f4)</li> </ul>"},{"location":"changelog/#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>Add overview page (6ad5c89)</li> </ul>"},{"location":"changelog/#v0010-2025-07-13","title":"v0.0.10 - 2025-07-13","text":"<p>Compare with v0.0.9</p>"},{"location":"changelog/#features_1","title":"\ud83d\ude80 Features","text":"<ul> <li>add public_prefix(and permanent_link) to libcloud (3bc7591)</li> <li>static_uuid transformer (88383e0)</li> <li>location transformers receive optional upload-or-data second argument (8e6a6dc)</li> </ul>"},{"location":"changelog/#bug-fixes_1","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>fix_extension transformer raises an error when upload is missing (a827df5)</li> </ul>"},{"location":"changelog/#removal","title":"\u274c Removal","text":"<ul> <li>delete Storage.public_link (da08744)</li> </ul>"},{"location":"changelog/#v009-2025-07-02","title":"v0.0.9 - 2025-07-02","text":"<p>Compare with v0.0.8</p>"},{"location":"changelog/#features_2","title":"\ud83d\ude80 Features","text":"<ul> <li>add fix_extension transformer (1345915)</li> <li>opendal got path option (d044ade)</li> </ul>"},{"location":"changelog/#bug-fixes_2","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>cast fs:multipart:position to int (dc4d768)</li> </ul>"},{"location":"changelog/#v008-2025-04-23","title":"v0.0.8 - 2025-04-23","text":"<p>Compare with v0.0.7</p>"},{"location":"changelog/#features_3","title":"\ud83d\ude80 Features","text":"<ul> <li>libcloud storage got path option (555036c)</li> </ul>"},{"location":"changelog/#bug-fixes_3","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>fs storage reports relative location of the missing file (cef9589)</li> </ul>"},{"location":"changelog/#v007-2025-03-28","title":"v0.0.7 - 2025-03-28","text":"<p>Compare with v0.0.6</p>"},{"location":"changelog/#features_4","title":"\ud83d\ude80 Features","text":"<ul> <li>storage upload and append requires Upload (ebf5fef)</li> </ul>"},{"location":"changelog/#bug-fixes_4","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>fs storage checks permission when creating folders (1791d68)</li> </ul>"},{"location":"changelog/#v006-2025-03-23","title":"v0.0.6 - 2025-03-23","text":"<p>Compare with v0.0.4</p>"},{"location":"changelog/#features_5","title":"\ud83d\ude80 Features","text":"<ul> <li>add *_synthetic methods (27c4164)</li> </ul>"},{"location":"changelog/#bug-fixes_5","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>multipart update of s3 and gcs work with arbitrary upload (902c9cb)</li> </ul>"},{"location":"changelog/#v004-2025-03-22","title":"v0.0.4 - 2025-03-22","text":"<p>Compare with v0.0.3</p>"},{"location":"changelog/#features_6","title":"\ud83d\ude80 Features","text":"<ul> <li>storages accept any type of upload (a64ee3d)</li> </ul>"},{"location":"changelog/#refactor_1","title":"\ud83d\ude9c Refactor","text":"<ul> <li>remove validation from storage (93392f9)</li> <li>remove type and size validation from append and compose (890c89a)</li> <li>remove public link method and capability (cb39151)</li> </ul>"},{"location":"changelog/#removal_1","title":"\u274c Removal","text":"<ul> <li>drop link storage (3328eb2)</li> </ul>"},{"location":"changelog/#v002-2025-03-17","title":"v0.0.2 - 2025-03-17","text":"<p>Compare with v0.0.1</p>"},{"location":"changelog/#features_7","title":"\ud83d\ude80 Features","text":"<ul> <li>stream-based composite implementation of range (7d47bd8)</li> <li>add Location wrapper around unsafe path parameters (b99f155)</li> <li>file_keeper:opendal adapter (214fb6c)</li> <li>file_keeper:redis adapter (8c7da94)</li> </ul>"},{"location":"changelog/#bug-fixes_6","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>map error during settings initialization into custom exception (f596037)</li> <li>fs adapter: infer <code>uploaded</code> size if it is not specified in <code>multipart_update</code> (620ec3a)</li> </ul>"},{"location":"changelog/#refactor_2","title":"\ud83d\ude9c Refactor","text":"<ul> <li><code>location_strategy: str</code> become <code>location_transformers: list[str]</code> (daf2dc6)</li> <li>remove default range implementation from reader (36f5f31)</li> </ul>"},{"location":"changelog/#testing","title":"\ud83e\uddea Testing","text":"<ul> <li>add standard adapter tests (d961682)</li> </ul>"},{"location":"changelog/#v001-2025-03-13","title":"v0.0.1 - 2025-03-13","text":""},{"location":"configuration/","title":"Configuration","text":"<p>Behavior of every storage is configurable through the Settings class. This page details the available settings and how to use them to customize your storage setup.</p>"},{"location":"configuration/#the-settings-class","title":"The Settings Class","text":"<p>The Settings class is the central point for configuring each storage adapter. It defines the options that control how the adapter interacts with the underlying storage.  Each adapter has its own subclass of Settings that adds adapter-specific options.</p> <p>While you can directly instantiate a Settings subclass with its arguments, the most common approach is to pass a dictionary of options to the storage adapter constructor. file-keeper automatically handles the transformation of this dictionary into a Settings object. This provides a more flexible and user-friendly configuration experience.</p> <p>Example</p> <p>Let's say you want to configure the S3 adapter. Instead of creating a Settings object directly, you can simply pass a dictionary like this:</p> <pre><code>from file_keeper import make_storage\n\ns3_settings = {\n    \"type\": \"file_keeper:s3\",\n    \"bucket\": \"my-s3-bucket\",\n    \"key\": \"YOUR_AWS_ACCESS_KEY_ID\",\n    \"secret\": \"YOUR_AWS_SECRET_ACCESS_KEY\",\n    \"region\": \"us-east-1\",\n}\n\nstorage = make_storage(\"my_s3_storage\", s3_settings)\n\n# Accessing the settings (for demonstration)\nprint(storage.settings.bucket) # (1)!\n</code></pre> <ol> <li>Output: my-s3-bucket</li> </ol> <p>In this example, <code>make_storage</code> automatically creates a <code>Settings</code> object from the <code>s3_settings</code> dictionary.</p>"},{"location":"configuration/#common-settings","title":"Common Settings","text":"<p>These settings are available for most storage adapters:</p> Setting Type Default Description <code>name</code> str <code>\"unknown\"</code> Descriptive name of the storage used for debugging. <code>override_existing</code> bool <code>False</code> If <code>True</code>, existing files will be overwritten during upload. If <code>False</code>, an <code>ExistingFileError</code> will be raised if a file with the same location already exists. <code>path</code> str <code>\"\"</code> The base path or directory where files are stored. The exact meaning depends on the adapter (e.g., a path in the filesystem for the FS adapter, a prefix-path inside the bucket for S3).  Required for most adapters. <code>location_transformers</code> list[str] <code>[]</code> A list of names of location transformers to apply to file locations. These transformers can be used to sanitize or modify file paths before they are used to store files. See the Extending file-keeper documentation for details. <code>disabled_capabilities</code> list[str] <code>[]</code> A list of capabilities to disable for the storage adapter. This can be useful for limiting the functionality of an adapter or for testing purposes. <code>initialize</code> bool <code>False</code> Prepare storage backend for uploads. The exact meaning depends on the adapter. Filesystem adapter created the upload folder if it's missing; cloud adapters create a bucket/container if it does not exists. <p>Important Considerations</p> Security Be careful when storing sensitive information like AWS access keys and secret keys in your configuration.  Consider using environment variables or a secure configuration management system. Validation file-keeper performs some basic validation of the configuration settings, but it's important to ensure that your settings are correct for your specific storage adapter. Error Handling Be prepared to handle <code>InvalidStorageConfigurationError</code> exceptions if your configuration is invalid."},{"location":"configuration/#adapter-specific-settings","title":"Adapter-Specific Settings","text":"<p>In addition to the common settings, adapters have their own specific settings:</p>"},{"location":"configuration/#file_keeperazure_blob","title":"<code>file_keeper:azure_blob</code>","text":"Setting Type Default Description <code>account_name</code> str <code>\"\"</code> Name of the account. <code>account_key</code> str <code>\"\"</code> Key for the account. <code>container_name</code> str <code>\"\"</code> Name of the storage container. <code>account_url</code> str <code>\"https://{account_name}.blob.core.windows.net\"</code> Custom resource URL. <code>client</code> BlobServiceClient <code>None</code> Existing storage client. <code>container</code> ContainerClient <code>None</code> Existing container client. <code>path</code> str <code>\"\"</code> Prefix for the file location. <code>initialize</code> bool <code>False</code> Create <code>container_name</code> if it does not exist."},{"location":"configuration/#file_keeperfilebin","title":"<code>file_keeper:filebin</code>","text":"Setting Type Default Description <code>bin</code> str <code>\"\"</code> The name of the bin. <code>timeout</code> int <code>10</code> Request timeout in seconds."},{"location":"configuration/#file_keeperfs","title":"<code>file_keeper:fs</code>","text":"Setting Type Default Description <code>path</code> str <code>\"\"</code> The base directory where files are stored. <code>initialize</code> bool <code>False</code> Create <code>path</code> if it does not exist."},{"location":"configuration/#file_keepergcs","title":"<code>file_keeper:gcs</code>","text":"Setting Type Default Description <code>bucket_name</code> str <code>\"\"</code> Name of the storage bucket. <code>client</code> Client <code>None</code> Existing storage client. <code>bucket</code> Bucket <code>None</code> Existing storage bucket. <code>credentials</code> Credentials <code>None</code> Existing cloud credentials. <code>credentials_file</code> str <code>\"\"</code> Path to the JSON with cloud credentials. <code>project_id</code> str <code>\"\"</code> The project which the client acts on behalf of. <code>client_options</code> dict <code>None</code> Client options for storage client. <code>path</code> str <code>\"\"</code> Prefix for the file location. <code>initialize</code> bool <code>False</code> Create <code>bucket_name</code> if it does not exist."},{"location":"configuration/#file_keeperlibcloud","title":"<code>file_keeper:libcloud</code>","text":"Setting Type Default Description <code>provider</code> str <code>\"\"</code> Name of the Libcloud provider <code>key</code> str <code>\"\"</code> Access key of the cloud account. <code>secret</code> str or None <code>None</code> Secret key of the cloud account. <code>params</code> dict <code>{}</code> Additional parameters for cloud provider. <code>container_name</code> str <code>\"\"</code> Name of the cloud container. <code>public_prefix</code> str <code>\"\"</code> Root URL for containers with public access. This URL will be used as a prefix for the file object location when building permanent links. <code>driver</code> StorageDriver <code>None</code> Existing storage driver. <code>container</code> Container <code>None</code> Existing container object. <code>path</code> str <code>\"\"</code> Prefix for the file location. <code>initialize</code> bool <code>False</code> Create <code>container_name</code> if it does not exist."},{"location":"configuration/#file_keepermemory","title":"<code>file_keeper:memory</code>","text":"Setting Type Default Description <code>bucket</code> MutableMapping[str, bytes] <code>{}</code> Container for uploaded objects."},{"location":"configuration/#file_keepernull","title":"<code>file_keeper:null</code>","text":"<p>No specific settings</p>"},{"location":"configuration/#file_keeperopendal","title":"<code>file_keeper:opendal</code>","text":"Setting Type Default Description <code>operator</code> opendal.Operator <code>None</code> Existing OpenDAL operator <code>scheme</code> str <code>\"\"</code> Name of OpenDAL operator's scheme. <code>params</code> dict <code>{}</code> Parameters for OpenDAL operator initialization. <code>path</code> str <code>\"\"</code> Prefix for the file location."},{"location":"configuration/#file_keeperproxy","title":"<code>file_keeper:proxy</code>","text":"Setting Type Default Description <code>adapter</code> str <code>None</code> Name of the proxified adapter. <code>options</code> dict <code>{}</code> Settings for the proxified adapter."},{"location":"configuration/#file_keeperredis","title":"<code>file_keeper:redis</code>","text":"Setting Type Default Description <code>redis</code> redis.Redis <code>None</code> Optional existing connection to Redis DB <code>url</code> str <code>\"\"</code> URL of the Redis DB. <code>bucket</code> str <code>\"\"</code> Key of the Redis HASH for uploaded objects."},{"location":"configuration/#file_keepers3","title":"<code>file_keeper:s3</code>","text":"Setting Type Default Description <code>bucket</code> str <code>\"\"</code> Name of the storage bucket. <code>client</code> S3Client <code>None\"</code> Existing S3 client. <code>key</code> str <code>None</code> The AWS Access Key. <code>secret</code> str <code>None</code> The AWS Secret Key. <code>region</code> str <code>None</code> The AWS Region of the bucket. <code>endpoint</code> str <code>None</code> Custom AWS endpoint. <code>path</code> str <code>\"\"</code> Prefix for the file location. <code>initialize</code> bool <code>False</code> Create <code>bucket</code> if it does not exist."},{"location":"configuration/#file_keepersqlalchemy","title":"<code>file_keeper:sqlalchemy</code>","text":"Setting Type Default Description <code>db_url</code> str <code>\"\"</code> URL of the storage DB. <code>table_name</code> str <code>\"\"</code> Name of the storage table. <code>location_column</code> str <code>\"\"</code> Name of the column that contains file location. <code>content_column</code> str <code>\"\"</code> Name of the column that contains file content. <code>engine</code> Engine <code>None</code> Existing DB engine. <code>table</code> Engine <code>None</code> Existing DB table. <code>location</code> Engine <code>None</code> Existing column for location. <code>content</code> Engine <code>None</code> Existing column for content. <code>initialize</code> bool <code>False</code> Create <code>table_name</code> if it does not exist."},{"location":"configuration/#file_keeperzip","title":"<code>file_keeper:zip</code>","text":"Setting Type Default Description <code>path</code> str <code>\"\"</code> Path of the ZIP archive for uploaded objects."},{"location":"error_handling/","title":"Error Handling","text":"<p>file-keeper provides a comprehensive set of exceptions to help you handle errors gracefully. This page documents the available exceptions and provides guidance on how to handle them.</p>"},{"location":"error_handling/#general-exception-hierarchy","title":"General Exception Hierarchy","text":"<p>All exceptions in file-keeper inherit from the base <code>FilesError</code> exception.  This allows you to catch all file-keeper related errors with a single <code>except</code> block.  More specific exceptions are derived from FilesError to provide more detailed error information.</p> <p>Note</p> <p>file-keeper's exceptions can be imported from <code>file_keeper.core.exceptions</code></p> <pre><code>from file_keeper.core.exceptions import FilesError\n\ntry:\n    ...\nexcept FilesError:\n    ...\n</code></pre> <p>As a shortcut, they can be accessed from the <code>exc</code> object available at the root of file-keeper module</p> <pre><code>from file_keeper import exc\n\ntry:\n    ...\nexcept exc.FilesError:\n    ...\n</code></pre>"},{"location":"error_handling/#example-error-handling","title":"Example Error Handling","text":"<pre><code>from file_keeper import make_storage, make_upload, exc\n\ntry:\n    storage = make_storage(\"my_storage\", {\"type\": \"file_keeper:fs\", \"path\": \"/nonexistent/path\"})\nexcept exc.InvalidStorageConfigurationError as e:\n    print(f\"Error configuring storage: {e}\")\n\nupload = make_upload(b\"Hello, file-keeper!\")\n\ntry:\n    storage.upload(\"my_file.txt\", upload)\nexcept exc.ExistingFileError as e:\n    print(f\"File already exists: {e}\")\n</code></pre>"},{"location":"error_handling/#file_keeper.exc","title":"<code>exc</code>","text":"<p>Exception definitions for the extension.</p> <p>Hierarchy:</p> <ul> <li>Exception<ul> <li>FilesError<ul> <li>StorageError<ul> <li>UnknownAdapterError</li> <li>UnknownStorageError</li> <li>UnsupportedOperationError</li> <li>PermissionError</li> <li>LocationError<ul> <li>MissingFileError</li> <li>ExistingFileError</li> </ul> </li> <li>ExtrasError<ul> <li>MissingExtrasError</li> </ul> </li> <li>InvalidStorageConfigurationError<ul> <li>MissingStorageConfigurationError</li> </ul> </li> <li>UploadError<ul> <li>WrongUploadTypeError</li> <li>LocationTransformerError</li> <li>ContentError</li> <li>LargeUploadError<ul> <li>UploadOutOfBoundError</li> </ul> </li> <li>UploadMismatchError<ul> <li>UploadTypeMismatchError</li> <li>UploadHashMismatchError</li> <li>UploadSizeMismatchError</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"error_handling/#file_keeper.exc.ContentError","title":"<code>ContentError(storage, msg)</code>","text":"<p>               Bases: <code>UploadError</code></p> <p>Storage cannot accept uploaded content.</p>"},{"location":"error_handling/#file_keeper.exc.ExistingFileError","title":"<code>ExistingFileError(storage, location)</code>","text":"<p>               Bases: <code>LocationError</code></p> <p>File already exists.</p>"},{"location":"error_handling/#file_keeper.exc.ExtrasError","title":"<code>ExtrasError(problem)</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Wrong extras passed during upload.</p>"},{"location":"error_handling/#file_keeper.exc.FilesError","title":"<code>FilesError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base error for catch-all scenario.</p>"},{"location":"error_handling/#file_keeper.exc.InvalidStorageConfigurationError","title":"<code>InvalidStorageConfigurationError(adapter_or_storage, problem)</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Storage cannot be initialized with given configuration.</p>"},{"location":"error_handling/#file_keeper.exc.LargeUploadError","title":"<code>LargeUploadError(actual_size, max_size)</code>","text":"<p>               Bases: <code>UploadError</code></p> <p>Storage cannot be initialized due to missing option.</p>"},{"location":"error_handling/#file_keeper.exc.LocationError","title":"<code>LocationError(storage, location)</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Storage cannot use given location.</p>"},{"location":"error_handling/#file_keeper.exc.LocationTransformerError","title":"<code>LocationTransformerError(transformer)</code>","text":"<p>               Bases: <code>UploadError</code></p> <p>Undefined location transformer.</p>"},{"location":"error_handling/#file_keeper.exc.MissingExtrasError","title":"<code>MissingExtrasError(key)</code>","text":"<p>               Bases: <code>ExtrasError</code></p> <p>Wrong extras passed to storage method.</p>"},{"location":"error_handling/#file_keeper.exc.MissingFileError","title":"<code>MissingFileError(storage, location)</code>","text":"<p>               Bases: <code>LocationError</code></p> <p>File does not exist.</p>"},{"location":"error_handling/#file_keeper.exc.MissingStorageConfigurationError","title":"<code>MissingStorageConfigurationError(adapter_or_storage, option)</code>","text":"<p>               Bases: <code>InvalidStorageConfigurationError</code></p> <p>Storage cannot be initialized due to missing option.</p>"},{"location":"error_handling/#file_keeper.exc.PermissionError","title":"<code>PermissionError(storage, operation, problem)</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Storage client does not have required permissions.</p>"},{"location":"error_handling/#file_keeper.exc.StorageError","title":"<code>StorageError</code>","text":"<p>               Bases: <code>FilesError</code></p> <p>Error related to storage.</p>"},{"location":"error_handling/#file_keeper.exc.UnknownAdapterError","title":"<code>UnknownAdapterError(adapter)</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Specified storage adapter is not registered.</p>"},{"location":"error_handling/#file_keeper.exc.UnknownStorageError","title":"<code>UnknownStorageError(storage)</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Storage with the given name is not configured.</p>"},{"location":"error_handling/#file_keeper.exc.UnsupportedOperationError","title":"<code>UnsupportedOperationError(operation, storage)</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Requested operation is not supported by storage.</p>"},{"location":"error_handling/#file_keeper.exc.UploadError","title":"<code>UploadError</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Error related to file upload process.</p>"},{"location":"error_handling/#file_keeper.exc.UploadHashMismatchError","title":"<code>UploadHashMismatchError(actual, expected)</code>","text":"<p>               Bases: <code>UploadMismatchError</code></p> <p>Expected value of hash match the actual value.</p>"},{"location":"error_handling/#file_keeper.exc.UploadMismatchError","title":"<code>UploadMismatchError(attribute, actual, expected)</code>","text":"<p>               Bases: <code>UploadError</code></p> <p>Expected value of file attribute doesn't match the actual value.</p>"},{"location":"error_handling/#file_keeper.exc.UploadOutOfBoundError","title":"<code>UploadOutOfBoundError(actual_size, max_size)</code>","text":"<p>               Bases: <code>LargeUploadError</code></p> <p>Ongoing upload exceeds expected size.</p>"},{"location":"error_handling/#file_keeper.exc.UploadSizeMismatchError","title":"<code>UploadSizeMismatchError(actual, expected)</code>","text":"<p>               Bases: <code>UploadMismatchError</code></p> <p>Expected value of upload size doesn't match the actual value.</p>"},{"location":"error_handling/#file_keeper.exc.UploadTypeMismatchError","title":"<code>UploadTypeMismatchError(actual, expected)</code>","text":"<p>               Bases: <code>UploadMismatchError</code></p> <p>Expected value of content type doesn't match the actual value.</p>"},{"location":"error_handling/#file_keeper.exc.WrongUploadTypeError","title":"<code>WrongUploadTypeError(content_type)</code>","text":"<p>               Bases: <code>UploadError</code></p> <p>Storage does not support given MIMEType.</p>"},{"location":"extending/","title":"Extending file-keeper","text":"<pre><code>*   How to create custom storage adapters.\n*   How to create custom upload factories.\n*   How to create custom location transformers.\n*   Example code snippets.\n</code></pre>"},{"location":"adapters/azure_blob/","title":"Azure Blob Storage","text":"<p><code>file_keeper:azure_blob</code></p>"},{"location":"adapters/emulate/","title":"Emulate cloud providers with Docker","text":"<p>For local development and testing, you can emulate cloud providers using Docker containers. This allows you to test your file-keeper integrations without incurring costs or requiring access to real cloud resources.</p> <p>Remember to adjust the port mappings and environment variables as needed for your specific setup.</p>"},{"location":"adapters/emulate/#minio-s3-compatible","title":"MinIO (S3-compatible)","text":"<pre><code>docker run -d -p 9000:9000 -p 9001:9001 \\\n    --name minio \\\n    -e MINIO_PUBLIC_ADDRESS=0.0.0.0:9000 \\\n    quay.io/minio/minio server /data --console-address \":9001\"\n</code></pre> <p>Default username and password set to <code>minioadmin</code>, endpoint available at <code>http://127.0.0.1:9000</code>.</p>"},{"location":"adapters/emulate/#azurite-azure-blob-storage","title":"Azurite (Azure Blob Storage)","text":"<pre><code>docker run -d -p 10000:10000 \\\n    --name azurite-blob \\\n    mcr.microsoft.com/azure-storage/azurite azurite-blob --blobHost 0.0.0.0\n</code></pre> <p>Default account name is <code>devstoreaccount1</code>. Default secret key is <code>Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==</code>. Endpoint available at <code>http://127.0.0.1:10000</code></p>"},{"location":"adapters/emulate/#fake-gcs-server-google-cloud-storage","title":"Fake GCS Server (Google Cloud Storage)","text":"<pre><code>docker run -d -p 4443:4443 \\\n     --name gcs \\\n     fsouza/fake-gcs-server -scheme http\n</code></pre> <p>Endpoint available at <code>http://127.0.0.1:4443</code> and does not requires credentials.</p>"},{"location":"adapters/filebin/","title":"Filebin","text":"<p><code>file_keeper:filebin</code></p>"},{"location":"adapters/fs/","title":"Local filesystem","text":"<p><code>file_keeper:fs</code></p> <p>No specific settings.</p> <p>If directory specified by <code>path</code> option does not exists, depending on <code>initialize</code> flag, storage will make an attempt to create <code>path</code> or rise InvalidStorageConfigurationError.</p> Storage initialization <pre><code>graph TD\n  check{&lt;code&gt;path&lt;/code&gt; exists?};\n  check_initialize{&lt;code&gt;initialize&lt;/code&gt; flag enabled?};\n  check_permission{Have permission to create &lt;code&gt;path&lt;/code&gt; hierarchy?};\n\n  no_work([Storage initialized]);\n  raise([raise InvalidStorageConfigurationError]);\n  create([Directories created and storage initialized]);\n\n  check --&gt;|Yes| no_work;\n  check --&gt;|No| check_initialize;\n  check_initialize --&gt;|No| raise;\n  check_initialize --&gt;|Yes| check_permission;\n  check_permission --&gt;|No| raise;\n  check_permission --&gt;|Yes| create;</code></pre> <p>Example</p> <pre><code>storage = make_storage(\"sandbox\", {\n    \"type\": \"file_keeper:fs\",\n    \"path\": \"/tmp/file-keeper\",\n    \"initialize\": True,\n})\n</code></pre>"},{"location":"adapters/gcs/","title":"Google Cloud Storage","text":"<p><code>file_keeper:gcs</code></p>"},{"location":"adapters/libcloud/","title":"Apache Libcloud","text":"<p><code>file_keeper:libcloud</code></p> <p>Example</p> <pre><code>storage = make_storage(\"sandbox\", {\n    \"type\": \"file_keeper:libcloud\",\n    \"provider\": \"MINIO\",\n    \"params\": {\"host\": \"127.0.0.1\", \"port\": 9000, \"secure\": False},\n    \"key\": \"***\", \"secret\": \"***\",\n    \"container_name\": \"file-keeper\",\n})\n</code></pre>"},{"location":"adapters/memory/","title":"Memory","text":"<p><code>file_keeper:memory</code></p>"},{"location":"adapters/null/","title":"Null","text":"<p><code>file_keeper:null</code></p>"},{"location":"adapters/opendal/","title":"Apache OpenDAL","text":"<p><code>file_keeper:opendal</code></p>"},{"location":"adapters/proxy/","title":"Proxy storage","text":"<p><code>file_keeper:proxy</code></p>"},{"location":"adapters/redis/","title":"Redis","text":"<p><code>file_keeper:redis</code></p> <p>Example</p> <pre><code>storage = make_storage(\"sandbox\", {\n    \"type\": \"file_keeper:redis\",\n    \"bucket\": \"file-keeper\"\n})\n</code></pre>"},{"location":"adapters/s3/","title":"AWS S3","text":"<p><code>file_keeper:s3</code></p> <p>Example</p> <pre><code>storage = make_storage(\"sandbox\", {\n    \"type\": \"file_keeper:s3\",\n    \"endpoint\": \"http://127.0.0.1:9000\",\n    \"key\": \"***\", \"secret\": \"***\",\n    \"bucket\": \"file-keeper\",\n})\n</code></pre>"},{"location":"adapters/sqlalchemy/","title":"SQLAlchemy","text":"<p><code>file_keeper:sqlalchemy</code></p>"},{"location":"adapters/zip/","title":"ZIP","text":"<p><code>file_keeper:zip</code></p>"},{"location":"core_concepts/capabilities/","title":"Capabilities","text":"<pre><code>*   Explanation of the `Capability` enum.\n*   How to check if a storage supports a specific operation.\n*   Examples of using capabilities.\n</code></pre>"},{"location":"core_concepts/data_model/","title":"Data model","text":"<pre><code>*   Explanation of `Storage`, `FileData`, `Location`.\n*   Attributes of each class.\n*   How these classes are used in different operations.\n</code></pre>"},{"location":"core_concepts/uploads/","title":"Upload","text":"<pre><code>*   Explanation of the `Upload` class.\n*   How to create an `Upload` object.\n*   Streaming uploads.\n*   Hashing.\n</code></pre>"}]}